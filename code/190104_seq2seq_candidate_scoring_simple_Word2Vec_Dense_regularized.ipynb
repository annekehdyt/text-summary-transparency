{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12344138650449566803\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequence = open_pickle('../../data/imdb/X_tr_sample_original.pkl')\n",
    "X_test_sequence = open_pickle('../../data/imdb/X_te_sample_original.pkl')\n",
    "y_train_target = open_pickle('../../data/imdb/y_tr_target_original.pkl')\n",
    "y_test_target = open_pickle('../../data/imdb/y_te_target_original.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('out with school girl and not in a good way there is even an extended montage of scene where the nostril picker is at school with the girl and a song plays over the top it is very possibly the worst song ever recorded i am not even going to describe it you will know it when you hear it and you will agree with me there are some scene of violence sure and there is a benny hill style chase',\n",
       " 'possibly the worst song ever')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 205\n",
    "\n",
    "X_train_sequence[idx], y_train_target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = [len(X.split()) for X in X_train_sequence]\n",
    "len_train = np.asarray(len_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len_train == 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_indices = np.where(len_train==True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   6,   8,   9,  10,  12,  13,  14,  15,  16,  17,  18,\n",
       "        20,  21,  22,  23,  26,  27,  31,  35,  36,  37,  38,  42,  44,\n",
       "        45,  46,  47,  50,  53,  54,  57,  58,  59,  60,  62,  63,  69,\n",
       "        73,  77,  79,  80,  83,  85,  90,  93,  95,  98, 100, 101, 103,\n",
       "       104, 105, 106, 108, 111, 113, 116, 117, 118, 120, 121, 123, 124,\n",
       "       132, 135, 137, 139, 145, 147, 149, 150, 152, 155, 159, 160, 161,\n",
       "       163, 165, 166, 167, 168, 171, 172, 173, 175, 177, 179, 184, 185,\n",
       "       190, 191, 194, 197, 200, 201, 204, 205, 206])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_indices[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# GLOVE_DIR = \"../../data/glove.6B/\"\n",
    "# GLOVE_DIM = 100\n",
    "\n",
    "# def extract_glove_index(file):\n",
    "#     embeddings_index = {}\n",
    "#     f = open(os.path.join(GLOVE_DIR, file), 'r')\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         coefs = np.asarray(values[1:], dtype='float32')\n",
    "#         embeddings_index[word] = coefs\n",
    "#     f.close()\n",
    "#     return embeddings_index\n",
    "\n",
    "# embeddings_index = extract_glove_index('glove.6B.100d.txt')\n",
    "# print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "train_sequence = []\n",
    "target_sequence = []\n",
    "\n",
    "for sample in X_train_sequence:\n",
    "    train_sequence.append(sample.split())\n",
    "for target in y_train_target:\n",
    "    target_sequence.append(target.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = gensim.models.Word2Vec(train_sequence,\n",
    "                                        size=EMBEDDING_DIM,\n",
    "                                        window=5,\n",
    "                                        workers=2,\n",
    "                                        sg=0)\n",
    "words = list(embedding_model.wv.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0964946e0288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'the'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_model['the'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 81\n",
    "max_decoder_seq_length = 5\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_sequence)\n",
    "\n",
    "X_tr_padded = pad_sequences(tokenizer.texts_to_sequences(X_train_sequence), maxlen=81, padding='post', truncating='post')\n",
    "y_tr_padded = pad_sequences(tokenizer.texts_to_sequences(y_train_target), maxlen=5, padding='post', truncating='post')\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(X_train_sequence), max_encoder_seq_length, EMBEDDING_DIM),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(y_train_target), max_decoder_seq_length, EMBEDDING_DIM),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(y_train_target), max_decoder_seq_length, len(words)),\n",
    "    dtype='float32')\n",
    "\n",
    "\n",
    "    \n",
    "# 100-dim -> input sequence, input decoder\n",
    "# 42K-dim -> output sequence.\n",
    "\n",
    "for i, (input_text, target_text, target_padded) in enumerate(zip(train_sequence, target_sequence, y_tr_padded)):\n",
    "    for t, word in enumerate(input_text):\n",
    "        try:\n",
    "            encoder_input_data[i, t, :] = embeddings_index[word]\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "    \n",
    "    for t, word in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        try:\n",
    "            decoder_input_data[i, t, :] = embeddings_index[word]\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "        \n",
    "    for t, word in enumerate(target_padded):\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, word] = 1.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 100\n",
    "NUM_ENCODER_TOKENS = np.max(X_tr_padded)\n",
    "NUM_DECODER_TOKENS = np.max(X_tr_padded)\n",
    "max_encoder_seq_length = X_tr_padded.shape[1]\n",
    "max_decoder_seq_length = X_tr_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42406"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DECODER_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42406"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(save_best_only=True, monitor='val_loss', filepath='./100_glove_best_model/weights.{epoch:04d}-{val_loss:.3f}.h5')\n",
    "csvlogger = CSVLogger(filename='glove_100_history.log', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "\n",
    "# encoder_inputs = Input(shape=(None, GLOVE_DIM))\n",
    "# encoder = LSTM(LATENT_DIM, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# decoder_inputs = Input(shape=(None, GLOVE_DIM))\n",
    "# decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                      initial_state=encoder_states)\n",
    "# decoder_dense = Dense(NUM_DECODER_TOKENS, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "# model = load_model('weights.0014-4.164.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15168 samples, validate on 7584 samples\n",
      "Epoch 1/1000\n",
      "15168/15168 [==============================] - 53s 3ms/step - loss: 3.8674 - val_loss: 4.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anneke/.local/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.8213 - val_loss: 4.0884\n",
      "Epoch 3/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.7758 - val_loss: 4.0501\n",
      "Epoch 4/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.7271 - val_loss: 4.0111\n",
      "Epoch 5/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.6825 - val_loss: 3.9785\n",
      "Epoch 6/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.6395 - val_loss: 3.9409\n",
      "Epoch 7/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.5981 - val_loss: 3.9144\n",
      "Epoch 8/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.5581 - val_loss: 3.8875\n",
      "Epoch 9/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.5204 - val_loss: 3.8652\n",
      "Epoch 10/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.4835 - val_loss: 3.8497\n",
      "Epoch 11/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.4489 - val_loss: 3.8230\n",
      "Epoch 12/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.4149 - val_loss: 3.8026\n",
      "Epoch 13/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.3839 - val_loss: 3.7863\n",
      "Epoch 14/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.3524 - val_loss: 3.7742\n",
      "Epoch 15/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 3.3209 - val_loss: 3.7552\n",
      "Epoch 16/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.2918 - val_loss: 3.7442\n",
      "Epoch 17/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.2633 - val_loss: 3.7326\n",
      "Epoch 18/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.2357 - val_loss: 3.7252\n",
      "Epoch 19/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.2077 - val_loss: 3.7117\n",
      "Epoch 20/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.1812 - val_loss: 3.7042\n",
      "Epoch 21/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.1531 - val_loss: 3.6914\n",
      "Epoch 22/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.1263 - val_loss: 3.6826\n",
      "Epoch 23/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.1001 - val_loss: 3.6780\n",
      "Epoch 24/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.0765 - val_loss: 3.6692\n",
      "Epoch 25/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.0530 - val_loss: 3.6646\n",
      "Epoch 26/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.0305 - val_loss: 3.6624\n",
      "Epoch 27/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 3.0070 - val_loss: 3.6550\n",
      "Epoch 28/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.9838 - val_loss: 3.6508\n",
      "Epoch 29/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.9651 - val_loss: 3.6570\n",
      "Epoch 30/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.9444 - val_loss: 3.6447\n",
      "Epoch 31/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.9204 - val_loss: 3.6407\n",
      "Epoch 32/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.8993 - val_loss: 3.6377\n",
      "Epoch 33/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.8796 - val_loss: 3.6354\n",
      "Epoch 34/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.8578 - val_loss: 3.6360\n",
      "Epoch 35/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.8386 - val_loss: 3.6332\n",
      "Epoch 36/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.8176 - val_loss: 3.6326\n",
      "Epoch 37/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.7973 - val_loss: 3.6301\n",
      "Epoch 38/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.7772 - val_loss: 3.6305\n",
      "Epoch 39/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 2.7572 - val_loss: 3.6319\n",
      "Epoch 40/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 2.7379 - val_loss: 3.6322\n",
      "Epoch 41/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.7184 - val_loss: 3.6290\n",
      "Epoch 42/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.6993 - val_loss: 3.6282\n",
      "Epoch 43/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.6802 - val_loss: 3.6283\n",
      "Epoch 44/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.6588 - val_loss: 3.6226\n",
      "Epoch 45/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.6335 - val_loss: 3.6200\n",
      "Epoch 46/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.6063 - val_loss: 3.6063\n",
      "Epoch 47/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.5774 - val_loss: 3.5948\n",
      "Epoch 48/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.5523 - val_loss: 3.5854\n",
      "Epoch 49/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.5254 - val_loss: 3.5739\n",
      "Epoch 50/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.4999 - val_loss: 3.5720\n",
      "Epoch 51/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.4740 - val_loss: 3.5609\n",
      "Epoch 52/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.4507 - val_loss: 3.5555\n",
      "Epoch 53/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.4274 - val_loss: 3.5506\n",
      "Epoch 54/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.4068 - val_loss: 3.5491\n",
      "Epoch 55/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.3837 - val_loss: 3.5439\n",
      "Epoch 56/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.3636 - val_loss: 3.5364\n",
      "Epoch 57/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.3423 - val_loss: 3.5344\n",
      "Epoch 58/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.3237 - val_loss: 3.5333\n",
      "Epoch 59/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.3040 - val_loss: 3.5306\n",
      "Epoch 60/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.2847 - val_loss: 3.5286\n",
      "Epoch 61/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.2643 - val_loss: 3.5265\n",
      "Epoch 62/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.2443 - val_loss: 3.5212\n",
      "Epoch 63/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.2264 - val_loss: 3.5185\n",
      "Epoch 64/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.2069 - val_loss: 3.5170\n",
      "Epoch 65/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.1876 - val_loss: 3.5131\n",
      "Epoch 66/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.1695 - val_loss: 3.5148\n",
      "Epoch 67/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.1532 - val_loss: 3.5096\n",
      "Epoch 68/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.1354 - val_loss: 3.5099\n",
      "Epoch 69/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.1196 - val_loss: 3.5100\n",
      "Epoch 70/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.0997 - val_loss: 3.5104\n",
      "Epoch 71/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.0829 - val_loss: 3.5113\n",
      "Epoch 72/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 2.0661 - val_loss: 3.5070\n",
      "Epoch 73/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.0504 - val_loss: 3.5016\n",
      "Epoch 74/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.0364 - val_loss: 3.5050\n",
      "Epoch 75/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.0194 - val_loss: 3.5080\n",
      "Epoch 76/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 2.0046 - val_loss: 3.5077\n",
      "Epoch 77/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.9893 - val_loss: 3.5083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.9737 - val_loss: 3.5061\n",
      "Epoch 79/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.9641 - val_loss: 3.5143\n",
      "Epoch 80/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.9491 - val_loss: 3.5106\n",
      "Epoch 81/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.9338 - val_loss: 3.5115\n",
      "Epoch 82/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.9198 - val_loss: 3.5118\n",
      "Epoch 83/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.9037 - val_loss: 3.5109\n",
      "Epoch 84/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.8933 - val_loss: 3.5153\n",
      "Epoch 85/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.8781 - val_loss: 3.5204\n",
      "Epoch 86/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.8700 - val_loss: 3.5220\n",
      "Epoch 87/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.8530 - val_loss: 3.5196\n",
      "Epoch 88/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.8416 - val_loss: 3.5266\n",
      "Epoch 89/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.8300 - val_loss: 3.5276\n",
      "Epoch 90/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.8166 - val_loss: 3.5284\n",
      "Epoch 91/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.8053 - val_loss: 3.5347\n",
      "Epoch 92/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.7938 - val_loss: 3.5294\n",
      "Epoch 93/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.7804 - val_loss: 3.5393\n",
      "Epoch 94/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.7727 - val_loss: 3.5451\n",
      "Epoch 95/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.7626 - val_loss: 3.5388\n",
      "Epoch 96/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.7483 - val_loss: 3.5468\n",
      "Epoch 97/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.7363 - val_loss: 3.5532\n",
      "Epoch 98/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.7266 - val_loss: 3.5524\n",
      "Epoch 99/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.7141 - val_loss: 3.5515\n",
      "Epoch 100/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.7052 - val_loss: 3.5511\n",
      "Epoch 101/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.6962 - val_loss: 3.5614\n",
      "Epoch 102/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.6877 - val_loss: 3.5634\n",
      "Epoch 103/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.6743 - val_loss: 3.5628\n",
      "Epoch 104/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.6623 - val_loss: 3.5767\n",
      "Epoch 105/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.6554 - val_loss: 3.5758\n",
      "Epoch 106/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.6436 - val_loss: 3.5748\n",
      "Epoch 107/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.6330 - val_loss: 3.5743\n",
      "Epoch 108/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.6254 - val_loss: 3.5831\n",
      "Epoch 109/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.6142 - val_loss: 3.5936\n",
      "Epoch 110/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.6060 - val_loss: 3.5994\n",
      "Epoch 111/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.5988 - val_loss: 3.5885\n",
      "Epoch 112/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.5879 - val_loss: 3.6027\n",
      "Epoch 113/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.5787 - val_loss: 3.5977\n",
      "Epoch 114/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.5708 - val_loss: 3.6065\n",
      "Epoch 115/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.5590 - val_loss: 3.6074\n",
      "Epoch 116/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.5526 - val_loss: 3.6123\n",
      "Epoch 117/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.5453 - val_loss: 3.6186\n",
      "Epoch 118/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.5343 - val_loss: 3.6280\n",
      "Epoch 119/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.5304 - val_loss: 3.6271\n",
      "Epoch 120/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.5162 - val_loss: 3.6327\n",
      "Epoch 121/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.5106 - val_loss: 3.6338\n",
      "Epoch 122/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.5011 - val_loss: 3.6345\n",
      "Epoch 123/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4950 - val_loss: 3.6532\n",
      "Epoch 124/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4846 - val_loss: 3.6428\n",
      "Epoch 125/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4761 - val_loss: 3.6541\n",
      "Epoch 126/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4705 - val_loss: 3.6565\n",
      "Epoch 127/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4634 - val_loss: 3.6620\n",
      "Epoch 128/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4531 - val_loss: 3.6701\n",
      "Epoch 129/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4474 - val_loss: 3.6725\n",
      "Epoch 130/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4416 - val_loss: 3.6784\n",
      "Epoch 131/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4334 - val_loss: 3.6791\n",
      "Epoch 132/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4246 - val_loss: 3.6780\n",
      "Epoch 133/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4200 - val_loss: 3.6818\n",
      "Epoch 134/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4079 - val_loss: 3.6891\n",
      "Epoch 135/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.4031 - val_loss: 3.6848\n",
      "Epoch 136/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3958 - val_loss: 3.7056\n",
      "Epoch 137/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3897 - val_loss: 3.7058\n",
      "Epoch 138/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3799 - val_loss: 3.7067\n",
      "Epoch 139/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3728 - val_loss: 3.7225\n",
      "Epoch 140/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3667 - val_loss: 3.7261\n",
      "Epoch 141/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3568 - val_loss: 3.7230\n",
      "Epoch 142/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3529 - val_loss: 3.7359\n",
      "Epoch 143/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3464 - val_loss: 3.7345\n",
      "Epoch 144/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3371 - val_loss: 3.7379\n",
      "Epoch 145/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.3297 - val_loss: 3.7411\n",
      "Epoch 146/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.3260 - val_loss: 3.7529\n",
      "Epoch 147/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.3190 - val_loss: 3.7564\n",
      "Epoch 148/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.3166 - val_loss: 3.7548\n",
      "Epoch 149/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.3046 - val_loss: 3.7544\n",
      "Epoch 150/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.2976 - val_loss: 3.7742\n",
      "Epoch 151/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.2914 - val_loss: 3.7746\n",
      "Epoch 152/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2900 - val_loss: 3.7747\n",
      "Epoch 153/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2783 - val_loss: 3.7871\n",
      "Epoch 154/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2747 - val_loss: 3.7862\n",
      "Epoch 155/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2675 - val_loss: 3.7876\n",
      "Epoch 156/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2596 - val_loss: 3.7966\n",
      "Epoch 157/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2535 - val_loss: 3.7994\n",
      "Epoch 158/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2474 - val_loss: 3.8051\n",
      "Epoch 159/1000\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 1.3220 - val_loss: 3.7939\n",
      "Epoch 160/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2698 - val_loss: 3.7919\n",
      "Epoch 161/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2451 - val_loss: 3.8068\n",
      "Epoch 162/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2245 - val_loss: 3.8122\n",
      "Epoch 163/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2147 - val_loss: 3.8178\n",
      "Epoch 164/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2074 - val_loss: 3.8215\n",
      "Epoch 165/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2078 - val_loss: 3.8342\n",
      "Epoch 166/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.2079 - val_loss: 3.8410\n",
      "Epoch 167/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1936 - val_loss: 3.8379\n",
      "Epoch 168/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1871 - val_loss: 3.8517\n",
      "Epoch 169/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1828 - val_loss: 3.8545\n",
      "Epoch 170/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1764 - val_loss: 3.8631\n",
      "Epoch 171/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1731 - val_loss: 3.8665\n",
      "Epoch 172/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1674 - val_loss: 3.8679\n",
      "Epoch 173/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1607 - val_loss: 3.8741\n",
      "Epoch 174/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1572 - val_loss: 3.8839\n",
      "Epoch 175/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1661 - val_loss: 3.8872\n",
      "Epoch 176/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1784 - val_loss: 3.8702\n",
      "Epoch 177/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1522 - val_loss: 3.8841\n",
      "Epoch 178/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1388 - val_loss: 3.8910\n",
      "Epoch 179/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1334 - val_loss: 3.8959\n",
      "Epoch 180/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1246 - val_loss: 3.8994\n",
      "Epoch 181/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1196 - val_loss: 3.9095\n",
      "Epoch 182/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1150 - val_loss: 3.9197\n",
      "Epoch 183/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1130 - val_loss: 3.9296\n",
      "Epoch 184/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.1088 - val_loss: 3.9361\n",
      "Epoch 185/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0997 - val_loss: 3.9343\n",
      "Epoch 186/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0987 - val_loss: 3.9334\n",
      "Epoch 187/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0984 - val_loss: 3.9388\n",
      "Epoch 188/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0892 - val_loss: 3.9378\n",
      "Epoch 189/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0787 - val_loss: 3.9575\n",
      "Epoch 190/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0764 - val_loss: 3.9596\n",
      "Epoch 191/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0704 - val_loss: 3.9560\n",
      "Epoch 192/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0732 - val_loss: 3.9666\n",
      "Epoch 193/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0646 - val_loss: 3.9730\n",
      "Epoch 194/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0532 - val_loss: 3.9883\n",
      "Epoch 195/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0572 - val_loss: 3.9952\n",
      "Epoch 196/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0541 - val_loss: 3.9924\n",
      "Epoch 197/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0417 - val_loss: 3.9943\n",
      "Epoch 198/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0371 - val_loss: 4.0108\n",
      "Epoch 199/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0389 - val_loss: 3.9924\n",
      "Epoch 200/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0322 - val_loss: 4.0047\n",
      "Epoch 201/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0260 - val_loss: 4.0225\n",
      "Epoch 202/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0232 - val_loss: 4.0198\n",
      "Epoch 203/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0212 - val_loss: 4.0203\n",
      "Epoch 204/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0174 - val_loss: 4.0229\n",
      "Epoch 205/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0090 - val_loss: 4.0301\n",
      "Epoch 206/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0009 - val_loss: 4.0469\n",
      "Epoch 207/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0014 - val_loss: 4.0485\n",
      "Epoch 208/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9949 - val_loss: 4.0558\n",
      "Epoch 209/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9917 - val_loss: 4.0539\n",
      "Epoch 210/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9964 - val_loss: 4.0602\n",
      "Epoch 211/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9857 - val_loss: 4.0646\n",
      "Epoch 212/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9894 - val_loss: 4.0673\n",
      "Epoch 213/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9762 - val_loss: 4.0773\n",
      "Epoch 214/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9743 - val_loss: 4.0831\n",
      "Epoch 215/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9670 - val_loss: 4.0806\n",
      "Epoch 216/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9641 - val_loss: 4.0943\n",
      "Epoch 217/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9670 - val_loss: 4.0970\n",
      "Epoch 218/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9571 - val_loss: 4.0990\n",
      "Epoch 219/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9537 - val_loss: 4.1157\n",
      "Epoch 220/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9443 - val_loss: 4.1067\n",
      "Epoch 221/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 1.0175 - val_loss: 4.0805\n",
      "Epoch 222/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9867 - val_loss: 4.0961\n",
      "Epoch 223/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9464 - val_loss: 4.1200\n",
      "Epoch 224/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9304 - val_loss: 4.1235\n",
      "Epoch 225/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9222 - val_loss: 4.1314\n",
      "Epoch 226/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9157 - val_loss: 4.1365\n",
      "Epoch 227/1000\n",
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9093 - val_loss: 4.1475\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15168/15168 [==============================] - 49s 3ms/step - loss: 0.9099 - val_loss: 4.1480\n",
      "Epoch 229/1000\n",
      " 2176/15168 [===>..........................] - ETA: 33s - loss: 0.8844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-05700953abeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           verbose=1, callbacks=[checkpoint, csvlogger])\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=(1./3),\n",
    "          verbose=1, callbacks=[checkpoint, csvlogger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "# model.save('100_glove_s2s_val_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./100_glove_best_model/weights.0073-3.502.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14936, 22277, 252, 21905, 26631, 269, 263219, 4578]\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_weights()\n",
    "\n",
    "s = []\n",
    "for w in weights:\n",
    "    s.append(np.sum(np.absolute(w)))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 42406)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008420034900721596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35706/(100*42406)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11020649"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias\n",
    "np.median(weights[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(weights[-2]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00840338214584525"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37343/4443806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 100), (None, 80400       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 100),  80400       input_4[0][0]                    \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 42406)  4283006     lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,443,806\n",
      "Trainable params: 4,443,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling models\n",
    "\n",
    "# https://nlp.stanford.edu/~johnhew/public/14-seq2seq.pdf\n",
    "# https://medium.com/machine-learning-bites/deeplearning-series-sequence-to-sequence-architectures-4c4ca89e5654\n",
    "\n",
    "model = load_model('./100_glove_best_model/weights.0073-3.502.h5')\n",
    "\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,), name='input_5')\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,), name='input_6')\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[3]\n",
    "\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "                    [decoder_inputs] + decoder_states_inputs,\n",
    "                    [decoder_outputs] + decoder_states\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict((i,word) for word,i in word_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_list(X):\n",
    "    y_candidate = []\n",
    "    \n",
    "    for i in range(X.shape[0]-1-5):\n",
    "        y_candidate.append(X[i:i+5])\n",
    "    \n",
    "    return np.asarray(y_candidate)\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "def target_index(doc_idx, candidate_seq, y):\n",
    "    for i,j in enumerate(candidate_seq):\n",
    "        if len(intersection(j, y)) == len(y):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# doc num, doc index argmax\n",
    "\n",
    "def to_sequence(int_sequence):\n",
    "    decoded = ''\n",
    "    for i in int_sequence:\n",
    "        if i == 0:\n",
    "            word = ' '\n",
    "        else:\n",
    "            word = reverse_word_index[i]\n",
    "        decoded += word + ' '\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_sequence[idx].split()\n",
    "len(X)\n",
    "y = []\n",
    "for i in range(len(X)-1-5):\n",
    "        y.append(' '.join(X[i:i+5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out with school girl and',\n",
       " 'with school girl and not',\n",
       " 'school girl and not in',\n",
       " 'girl and not in a',\n",
       " 'and not in a good',\n",
       " 'not in a good way',\n",
       " 'in a good way there',\n",
       " 'a good way there is',\n",
       " 'good way there is even',\n",
       " 'way there is even an',\n",
       " 'there is even an extended',\n",
       " 'is even an extended montage',\n",
       " 'even an extended montage of',\n",
       " 'an extended montage of scene',\n",
       " 'extended montage of scene where',\n",
       " 'montage of scene where the',\n",
       " 'of scene where the nostril',\n",
       " 'scene where the nostril picker',\n",
       " 'where the nostril picker is',\n",
       " 'the nostril picker is at',\n",
       " 'nostril picker is at school',\n",
       " 'picker is at school with',\n",
       " 'is at school with the',\n",
       " 'at school with the girl',\n",
       " 'school with the girl and',\n",
       " 'with the girl and a',\n",
       " 'the girl and a song',\n",
       " 'girl and a song plays',\n",
       " 'and a song plays over',\n",
       " 'a song plays over the',\n",
       " 'song plays over the top',\n",
       " 'plays over the top it',\n",
       " 'over the top it is',\n",
       " 'the top it is very',\n",
       " 'top it is very possibly',\n",
       " 'it is very possibly the',\n",
       " 'is very possibly the worst',\n",
       " 'very possibly the worst song',\n",
       " 'possibly the worst song ever',\n",
       " 'the worst song ever recorded',\n",
       " 'worst song ever recorded i',\n",
       " 'song ever recorded i am',\n",
       " 'ever recorded i am not',\n",
       " 'recorded i am not even',\n",
       " 'i am not even going',\n",
       " 'am not even going to',\n",
       " 'not even going to describe',\n",
       " 'even going to describe it',\n",
       " 'going to describe it you',\n",
       " 'to describe it you will',\n",
       " 'describe it you will know',\n",
       " 'it you will know it',\n",
       " 'you will know it when',\n",
       " 'will know it when you',\n",
       " 'know it when you hear',\n",
       " 'it when you hear it',\n",
       " 'when you hear it and',\n",
       " 'you hear it and you',\n",
       " 'hear it and you will',\n",
       " 'it and you will agree',\n",
       " 'and you will agree with',\n",
       " 'you will agree with me',\n",
       " 'will agree with me there',\n",
       " 'agree with me there are',\n",
       " 'with me there are some',\n",
       " 'me there are some scene',\n",
       " 'there are some scene of',\n",
       " 'are some scene of violence',\n",
       " 'some scene of violence sure',\n",
       " 'scene of violence sure and',\n",
       " 'of violence sure and there',\n",
       " 'violence sure and there is',\n",
       " 'sure and there is a',\n",
       " 'and there is a benny',\n",
       " 'there is a benny hill']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = tokenizer.index_word\n",
    "# index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with candidate\n",
    "\n",
    "def decode_sequence_target(candidate_states_value, candidate_target_seq):\n",
    "#     candidate_states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    from_candidate_target_seq = np.zeros((1,1, GLOVE_DIM))\n",
    "    \n",
    "    candidate_token_index = candidate_target_seq[0,0]\n",
    "    try:\n",
    "        from_candidate_target_seq[0,0,:] = embeddings_index[index_word[candidate_token_index]]\n",
    "    except KeyError as error:\n",
    "        pass\n",
    "    \n",
    "    candidate_joint_log_prob = 0\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        from_candidate_output_tokens, h_true, c_true = decoder_model.predict([from_candidate_target_seq] + candidate_states_value)\n",
    "    \n",
    "        candidate_target_prob = from_candidate_output_tokens[0,-1, candidate_target_seq[0,i]]\n",
    "        candidate_joint_log_prob += np.log(candidate_target_prob)\n",
    "        \n",
    "        # get the t+1 input\n",
    "        \n",
    "        candidate_token_index = candidate_target_seq[0,i]\n",
    "        from_candidate_target_seq = np.zeros((1,1,GLOVE_DIM))\n",
    "        try:\n",
    "            from_candidate_target_seq[0,0,:] = embeddings_index[index_word[candidate_token_index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        candidate_states_value = [h_true, c_true]\n",
    "\n",
    "    return candidate_joint_log_prob, candidate_target_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "file = open(\"candidate_jll_glove_100_best.csv\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 0...\n",
      "Processing document 100...\n",
      "Processing document 200...\n",
      "Processing document 300...\n",
      "Processing document 400...\n",
      "Processing document 500...\n",
      "Processing document 600...\n",
      "Processing document 700...\n",
      "Processing document 800...\n",
      "Processing document 900...\n",
      "Processing document 1000...\n",
      "Processing document 1100...\n",
      "Processing document 1200...\n",
      "Processing document 1300...\n",
      "Processing document 1400...\n",
      "Processing document 1500...\n",
      "Processing document 1600...\n",
      "Processing document 1700...\n",
      "Processing document 1800...\n",
      "Processing document 1900...\n",
      "Processing document 2000...\n",
      "Processing document 2100...\n",
      "Processing document 2200...\n",
      "Processing document 2300...\n",
      "Processing document 2400...\n",
      "Processing document 2500...\n",
      "Processing document 2600...\n",
      "Processing document 2700...\n",
      "Processing document 2800...\n",
      "Processing document 2900...\n",
      "Processing document 3000...\n",
      "Processing document 3100...\n",
      "Processing document 3200...\n",
      "Processing document 3300...\n",
      "Processing document 3400...\n",
      "Processing document 3500...\n",
      "Processing document 3600...\n",
      "Processing document 3700...\n",
      "Processing document 3800...\n",
      "Processing document 3900...\n",
      "Processing document 4000...\n",
      "Processing document 4100...\n",
      "Processing document 4200...\n",
      "Processing document 4300...\n",
      "Processing document 4400...\n",
      "Processing document 4500...\n",
      "Processing document 4600...\n",
      "Processing document 4700...\n",
      "Processing document 4800...\n",
      "Processing document 4900...\n",
      "Processing document 5000...\n",
      "Processing document 5100...\n",
      "Processing document 5200...\n",
      "Processing document 5300...\n",
      "Processing document 5400...\n",
      "Processing document 5500...\n",
      "Processing document 5600...\n",
      "Processing document 5700...\n",
      "Processing document 5800...\n",
      "Processing document 5900...\n",
      "Processing document 6000...\n",
      "Processing document 6100...\n",
      "Processing document 6200...\n",
      "Processing document 6300...\n",
      "Processing document 6400...\n",
      "Processing document 6500...\n",
      "Processing document 6600...\n",
      "Processing document 6700...\n",
      "Processing document 6800...\n",
      "Processing document 6900...\n",
      "Processing document 7000...\n",
      "Processing document 7100...\n",
      "Processing document 7200...\n",
      "Processing document 7300...\n",
      "Processing document 7400...\n",
      "Processing document 7500...\n",
      "Processing document 7600...\n",
      "Processing document 7700...\n",
      "Processing document 7800...\n",
      "Processing document 7900...\n",
      "Processing document 8000...\n",
      "Processing document 8100...\n",
      "Processing document 8200...\n",
      "Processing document 8300...\n",
      "Processing document 8400...\n",
      "Processing document 8500...\n",
      "Processing document 8600...\n",
      "Processing document 8700...\n",
      "Processing document 8800...\n",
      "Processing document 8900...\n",
      "Processing document 9000...\n",
      "Processing document 9100...\n",
      "Processing document 9200...\n",
      "Processing document 9300...\n",
      "Processing document 9400...\n",
      "Processing document 9500...\n",
      "Processing document 9600...\n",
      "Processing document 9700...\n",
      "Processing document 9800...\n",
      "Processing document 9900...\n",
      "Processing document 10000...\n",
      "Processing document 10100...\n",
      "Processing document 10200...\n",
      "Processing document 10300...\n",
      "Processing document 10400...\n",
      "Processing document 10500...\n",
      "Processing document 10600...\n",
      "Processing document 10700...\n",
      "Processing document 10800...\n",
      "Processing document 10900...\n",
      "Processing document 11000...\n",
      "Processing document 11100...\n",
      "Processing document 11200...\n",
      "Processing document 11300...\n",
      "Processing document 11400...\n",
      "Processing document 11500...\n",
      "Processing document 11600...\n",
      "Processing document 11700...\n",
      "Processing document 11800...\n",
      "Processing document 11900...\n",
      "Processing document 12000...\n",
      "Processing document 12100...\n",
      "Processing document 12200...\n",
      "Processing document 12300...\n",
      "Processing document 12400...\n",
      "Processing document 12500...\n",
      "Processing document 12600...\n",
      "Processing document 12700...\n",
      "Processing document 12800...\n",
      "Processing document 12900...\n",
      "Processing document 13000...\n",
      "Processing document 13100...\n",
      "Processing document 13200...\n",
      "Processing document 13300...\n",
      "Processing document 13400...\n",
      "Processing document 13500...\n",
      "Processing document 13600...\n",
      "Processing document 13700...\n",
      "Processing document 13800...\n",
      "Processing document 13900...\n",
      "Processing document 14000...\n",
      "Processing document 14100...\n",
      "Processing document 14200...\n",
      "Processing document 14300...\n",
      "Processing document 14400...\n",
      "Processing document 14500...\n",
      "Processing document 14600...\n",
      "Processing document 14700...\n",
      "Processing document 14800...\n",
      "Processing document 14900...\n",
      "Processing document 15000...\n",
      "Processing document 15100...\n",
      "Processing document 15200...\n",
      "Processing document 15300...\n",
      "Processing document 15400...\n",
      "Processing document 15500...\n",
      "Processing document 15600...\n",
      "Processing document 15700...\n",
      "Processing document 15800...\n",
      "Processing document 15900...\n",
      "Processing document 16000...\n",
      "Processing document 16100...\n",
      "Processing document 16200...\n",
      "Processing document 16300...\n",
      "Processing document 16400...\n",
      "Processing document 16500...\n",
      "Processing document 16600...\n",
      "Processing document 16700...\n",
      "Processing document 16800...\n",
      "Processing document 16900...\n",
      "Processing document 17000...\n",
      "Processing document 17100...\n",
      "Processing document 17200...\n",
      "Processing document 17300...\n",
      "Processing document 17400...\n",
      "Processing document 17500...\n",
      "Processing document 17600...\n",
      "Processing document 17700...\n",
      "Processing document 17800...\n",
      "Processing document 17900...\n",
      "Processing document 18000...\n",
      "Processing document 18100...\n",
      "Processing document 18200...\n",
      "Processing document 18300...\n",
      "Processing document 18400...\n",
      "Processing document 18500...\n",
      "Processing document 18600...\n",
      "Processing document 18700...\n",
      "Processing document 18800...\n",
      "Processing document 18900...\n",
      "Processing document 19000...\n",
      "Processing document 19100...\n",
      "Processing document 19200...\n",
      "Processing document 19300...\n",
      "Processing document 19400...\n",
      "Processing document 19500...\n",
      "Processing document 19600...\n",
      "Processing document 19700...\n",
      "Processing document 19800...\n",
      "Processing document 19900...\n",
      "Processing document 20000...\n",
      "Processing document 20100...\n",
      "Processing document 20200...\n",
      "Processing document 20300...\n",
      "Processing document 20400...\n",
      "Processing document 20500...\n",
      "Processing document 20600...\n",
      "Processing document 20700...\n",
      "Processing document 20800...\n",
      "Processing document 20900...\n",
      "Processing document 21000...\n",
      "Processing document 21100...\n",
      "Processing document 21200...\n",
      "Processing document 21300...\n",
      "Processing document 21400...\n",
      "Processing document 21500...\n",
      "Processing document 21600...\n",
      "Processing document 21700...\n",
      "Processing document 21800...\n",
      "Processing document 21900...\n",
      "Processing document 22000...\n",
      "Processing document 22100...\n",
      "Processing document 22200...\n",
      "Processing document 22300...\n",
      "Processing document 22400...\n",
      "Processing document 22500...\n",
      "Processing document 22600...\n",
      "Processing document 22700...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 42406 is out of bounds for axis 2 with size 42406",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-793d47542fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_candidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcandidate_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_last_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcandidate_jll_per_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-37055bc58994>\u001b[0m in \u001b[0;36mdecode_sequence_target\u001b[0;34m(candidate_states_value, candidate_target_seq)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrom_candidate_target_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcandidate_target_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcandidate_joint_log_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_target_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 42406 is out of bounds for axis 2 with size 42406"
     ]
    }
   ],
   "source": [
    "for doc in X_tr_padded:\n",
    "    y_candidate = generate_candidate_list(doc)\n",
    "    \n",
    "    candidate_jll_per_doc = []\n",
    "    input_seq = encoder_input_data[i:i+1]\n",
    "    \n",
    "    true_target_index = target_index(i, y_candidate, y_tr_padded[i])\n",
    "    \n",
    "    # Encode\n",
    "    candidate_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    for j in range(y_candidate.shape[0]):\n",
    "        candidate_seq = y_candidate[j:j+1]\n",
    "        candidate_jll_slide, candidate_last_prob = decode_sequence_target(candidate_states_value, candidate_seq)\n",
    "        candidate_jll_per_doc.append(candidate_jll_slide)\n",
    "\n",
    "    candidate_jll_per_doc = np.asarray(candidate_jll_per_doc)\n",
    "    max_jll_index = np.argmax(candidate_jll_per_doc)\n",
    "    true_target_jll = np.around(candidate_jll_per_doc[true_target_index],5)\n",
    "    max_candidate_jll = np.around(candidate_jll_per_doc[max_jll_index],5)\n",
    "    \n",
    "    \n",
    "    file.write('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\n' %(i, true_target_index, y_train_target[i],\n",
    "                                                            max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "                                                            -(true_target_index-max_jll_index),\n",
    "                                                            true_target_jll, max_candidate_jll,\n",
    "                                                            np.absolute(true_target_jll-max_candidate_jll),\n",
    "                                                            len(intersection(y_tr_padded[i], y_candidate[max_jll_index])),\n",
    "                                                            np.exp(true_target_jll/4), np.exp(max_candidate_jll/4)))\n",
    "    \n",
    "#     print('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\n' %(i, true_target_index, y['text'][i],\n",
    "#                                                             max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "#                                                             -(true_target_index-max_jll_index),\n",
    "#                                                             true_target_jll, max_candidate_jll,\n",
    "#                                                             np.absolute(true_target_jll-max_candidate_jll),\n",
    "#                                                             len(intersection(y['padded'][i], y_candidate[max_jll_index]))))\n",
    "    if i % 100 == 0:\n",
    "        print('Processing document %d...' %(i))\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import CSVLogger\n",
    "\n",
    "# csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start test data preprocessing\n",
    "\n",
    "X_te = open_pickle('../../data/imdb_sequence/3000_one_hot/X_te_seq_set.pkl')\n",
    "y_te = open_pickle('../../data/imdb_sequence/3000_one_hot/y_te_seq_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 81\n",
    "max_decoder_seq_length = 5\n",
    "\n",
    "X_te_padded = pad_sequences(tokenizer.texts_to_sequences(X_test_sequence), maxlen=81, padding='post', truncating='post')\n",
    "y_te_padded = pad_sequences(tokenizer.texts_to_sequences(y_test_target), maxlen=5, padding='post', truncating='post')\n",
    "\n",
    "test_encoder_input_data = np.zeros(\n",
    "    (len(X_test_sequence), max_encoder_seq_length, GLOVE_DIM),\n",
    "    dtype='float32')\n",
    "test_decoder_input_data = np.zeros(\n",
    "    (len(y_test_target), max_decoder_seq_length, GLOVE_DIM),\n",
    "    dtype='float32')\n",
    "test_decoder_target_data = np.zeros(\n",
    "    (len(y_test_target), max_decoder_seq_length, len(tokenizer.word_index)),\n",
    "    dtype='float32')\n",
    "\n",
    "test_sequence = []\n",
    "test_target_sequence = []\n",
    "\n",
    "for sample in X_test_sequence:\n",
    "    test_sequence.append(sample.split())\n",
    "for target in y_test_target:\n",
    "    test_target_sequence.append(target.split())\n",
    "    \n",
    "# 100-dim -> input sequence, input decoder\n",
    "# 42K-dim -> output sequence.\n",
    "\n",
    "for i, (input_text, target_text, target_padded) in enumerate(zip(test_sequence, test_target_sequence, y_tr_padded)):\n",
    "    for t, word in enumerate(input_text):\n",
    "        try:\n",
    "            test_encoder_input_data[i, t, :] = embeddings_index[word]\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "    \n",
    "    for t, word in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        try:\n",
    "            test_decoder_input_data[i, t, :] = embeddings_index[word]\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "        \n",
    "    for t, word in enumerate(target_padded):\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            test_decoder_target_data[i, t - 1, word] = 1.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with candidate\n",
    "\n",
    "def test_decode_sequence_target(candidate_states_value, candidate_target_seq):\n",
    "#     candidate_states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    from_candidate_target_seq = np.zeros((1,1, GLOVE_DIM))\n",
    "    \n",
    "    candidate_token_index = candidate_target_seq[0,0]\n",
    "    try:\n",
    "        from_candidate_target_seq[0,0,:] = embeddings_index[index_word[candidate_token_index]]\n",
    "    except KeyError as error:\n",
    "        pass\n",
    "    \n",
    "    candidate_joint_log_prob = 0\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        from_candidate_output_tokens, h_true, c_true = decoder_model.predict([from_candidate_target_seq] + candidate_states_value)\n",
    "    \n",
    "        candidate_target_prob = from_candidate_output_tokens[0,-1, candidate_target_seq[0,i]]\n",
    "        candidate_joint_log_prob += np.log(candidate_target_prob)\n",
    "        \n",
    "        # get the t+1 input\n",
    "        \n",
    "        candidate_token_index = candidate_target_seq[0,i]\n",
    "        from_candidate_target_seq = np.zeros((1,1,GLOVE_DIM))\n",
    "        try:\n",
    "            from_candidate_target_seq[0,0,:] = embeddings_index[index_word[candidate_token_index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        candidate_states_value = [h_true, c_true]\n",
    "\n",
    "    return candidate_joint_log_prob, candidate_target_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3680\n",
    "start = 3680\n",
    "\n",
    "file = open(\"test_candidate_jll_100_glove_best.csv\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 3700...\n",
      "Processing document 3800...\n",
      "Processing document 3900...\n",
      "Processing document 4000...\n",
      "Processing document 4100...\n",
      "Processing document 4200...\n",
      "Processing document 4300...\n",
      "Processing document 4400...\n",
      "Processing document 4500...\n",
      "Processing document 4600...\n",
      "Processing document 4700...\n",
      "Processing document 4800...\n",
      "Processing document 4900...\n",
      "Processing document 5000...\n",
      "Processing document 5100...\n",
      "Processing document 5200...\n",
      "Processing document 5300...\n",
      "Processing document 5400...\n",
      "Processing document 5500...\n",
      "Processing document 5600...\n",
      "Processing document 5700...\n",
      "Processing document 5800...\n",
      "Processing document 5900...\n",
      "Processing document 6000...\n",
      "Processing document 6100...\n",
      "Processing document 6200...\n",
      "Processing document 6300...\n",
      "Processing document 6400...\n",
      "Processing document 6500...\n",
      "Processing document 6600...\n",
      "Processing document 6700...\n",
      "Processing document 6800...\n",
      "Processing document 6900...\n",
      "Processing document 7000...\n",
      "Processing document 7100...\n",
      "Processing document 7200...\n",
      "Processing document 7300...\n",
      "Processing document 7400...\n",
      "Processing document 7500...\n",
      "Processing document 7600...\n",
      "Processing document 7700...\n",
      "Processing document 7800...\n",
      "Processing document 7900...\n",
      "Processing document 8000...\n",
      "Processing document 8100...\n",
      "Processing document 8200...\n",
      "Processing document 8300...\n",
      "Processing document 8400...\n",
      "Processing document 8500...\n",
      "Processing document 8600...\n",
      "Processing document 8700...\n",
      "Processing document 8800...\n",
      "Processing document 8900...\n",
      "Processing document 9000...\n",
      "Processing document 9100...\n",
      "Processing document 9200...\n",
      "Processing document 9300...\n",
      "Processing document 9400...\n",
      "Processing document 9500...\n",
      "Processing document 9600...\n",
      "Processing document 9700...\n",
      "Processing document 9800...\n",
      "Processing document 9900...\n",
      "Processing document 10000...\n",
      "Processing document 10100...\n",
      "Processing document 10200...\n",
      "Processing document 10300...\n",
      "Processing document 10400...\n",
      "Processing document 10500...\n",
      "Processing document 10600...\n",
      "Processing document 10700...\n",
      "Processing document 10800...\n",
      "Processing document 10900...\n",
      "Processing document 11000...\n",
      "Processing document 11100...\n",
      "Processing document 11200...\n",
      "Processing document 11300...\n",
      "Processing document 11400...\n",
      "Processing document 11500...\n",
      "Processing document 11600...\n",
      "Processing document 11700...\n",
      "Processing document 11800...\n",
      "Processing document 11900...\n",
      "Processing document 12000...\n",
      "Processing document 12100...\n",
      "Processing document 12200...\n",
      "Processing document 12300...\n",
      "Processing document 12400...\n",
      "Processing document 12500...\n",
      "Processing document 12600...\n",
      "Processing document 12700...\n",
      "Processing document 12800...\n",
      "Processing document 12900...\n",
      "Processing document 13000...\n",
      "Processing document 13100...\n",
      "Processing document 13200...\n",
      "Processing document 13300...\n",
      "Processing document 13400...\n",
      "Processing document 13500...\n",
      "Processing document 13600...\n",
      "Processing document 13700...\n",
      "Processing document 13800...\n",
      "Processing document 13900...\n",
      "Processing document 14000...\n",
      "Processing document 14100...\n",
      "Processing document 14200...\n",
      "Processing document 14300...\n",
      "Processing document 14400...\n",
      "Processing document 14500...\n",
      "Processing document 14600...\n",
      "Processing document 14700...\n",
      "Processing document 14800...\n",
      "Processing document 14900...\n",
      "Processing document 15000...\n",
      "Processing document 15100...\n",
      "Processing document 15200...\n",
      "Processing document 15300...\n",
      "Processing document 15400...\n",
      "Processing document 15500...\n",
      "Processing document 15600...\n",
      "Processing document 15700...\n",
      "Processing document 15800...\n",
      "Processing document 15900...\n",
      "Processing document 16000...\n",
      "Processing document 16100...\n",
      "Processing document 16200...\n",
      "Processing document 16300...\n",
      "Processing document 16400...\n",
      "Processing document 16500...\n",
      "Processing document 16600...\n",
      "Processing document 16700...\n",
      "Processing document 16800...\n",
      "Processing document 16900...\n",
      "Processing document 17000...\n",
      "Processing document 17100...\n",
      "Processing document 17200...\n",
      "Processing document 17300...\n",
      "Processing document 17400...\n",
      "Processing document 17500...\n",
      "Processing document 17600...\n",
      "Processing document 17700...\n",
      "Processing document 17800...\n",
      "Processing document 17900...\n",
      "Processing document 18000...\n",
      "Processing document 18100...\n",
      "Processing document 18200...\n",
      "Processing document 18300...\n",
      "Processing document 18400...\n",
      "Processing document 18500...\n",
      "Processing document 18600...\n",
      "Processing document 18700...\n",
      "Processing document 18800...\n",
      "Processing document 18900...\n",
      "Processing document 19000...\n",
      "Processing document 19100...\n",
      "Processing document 19200...\n",
      "Processing document 19300...\n",
      "Processing document 19400...\n",
      "Processing document 19500...\n",
      "Processing document 19600...\n",
      "Processing document 19700...\n",
      "Processing document 19800...\n",
      "Processing document 19900...\n",
      "Processing document 20000...\n",
      "Processing document 20100...\n",
      "Processing document 20200...\n",
      "Processing document 20300...\n",
      "Processing document 20400...\n",
      "Processing document 20500...\n",
      "Processing document 20600...\n",
      "Processing document 20700...\n",
      "Processing document 20800...\n",
      "Processing document 20900...\n",
      "Processing document 21000...\n",
      "Processing document 21100...\n",
      "Processing document 21200...\n",
      "Processing document 21300...\n",
      "Processing document 21400...\n",
      "Processing document 21500...\n",
      "Processing document 21600...\n",
      "Processing document 21700...\n",
      "Processing document 21800...\n",
      "Processing document 21900...\n",
      "Processing document 22000...\n",
      "Processing document 22100...\n",
      "Processing document 22200...\n",
      "Processing document 22300...\n",
      "Processing document 22400...\n",
      "Processing document 22500...\n",
      "Processing document 22600...\n",
      "Processing document 22700...\n"
     ]
    }
   ],
   "source": [
    "for doc in X_te_padded[start:]:\n",
    "    y_candidate = generate_candidate_list(doc)\n",
    "    \n",
    "    candidate_jll_per_doc = []\n",
    "    input_seq = test_encoder_input_data[i:i+1]\n",
    "    \n",
    "    true_target_index = target_index(i, y_candidate, y_te_padded[i])\n",
    "    \n",
    "    # Encode\n",
    "    candidate_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    for j in range(y_candidate.shape[0]):\n",
    "        candidate_seq = y_candidate[j:j+1]\n",
    "        candidate_jll_slide, candidate_last_prob = test_decode_sequence_target(candidate_states_value, candidate_seq)\n",
    "        candidate_jll_per_doc.append(candidate_jll_slide)\n",
    "\n",
    "    candidate_jll_per_doc = np.asarray(candidate_jll_per_doc)\n",
    "    max_jll_index = np.argmax(candidate_jll_per_doc)\n",
    "    true_target_jll = np.around(candidate_jll_per_doc[true_target_index],5)\n",
    "    max_candidate_jll = np.around(candidate_jll_per_doc[max_jll_index],5)\n",
    "    \n",
    "    \n",
    "    file.write('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\n' %(i, true_target_index, y_test_target[i],\n",
    "                                                            max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "                                                            -(true_target_index-max_jll_index),\n",
    "                                                            true_target_jll, max_candidate_jll,\n",
    "                                                            np.absolute(true_target_jll-max_candidate_jll),\n",
    "                                                            len(intersection(y_te_padded[i], y_candidate[max_jll_index])),\n",
    "                                                            np.exp(true_target_jll/4), np.exp(max_candidate_jll/4)))\n",
    "    \n",
    "#     print('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\n' %(i, true_target_index, y['text'][i],\n",
    "#                                                             max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "#                                                             -(true_target_index-max_jll_index),\n",
    "#                                                             true_target_jll, max_candidate_jll,\n",
    "#                                                             np.absolute(true_target_jll-max_candidate_jll),\n",
    "#                                                             len(intersection(y['padded'][i], y_candidate[max_jll_index]))))\n",
    "    if i % 100 == 0:\n",
    "        print('Processing document %d...' %(i))\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
