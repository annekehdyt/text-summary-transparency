{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "from slacker import Slacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3381833774549083369\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7524958208\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 11321584302467032114\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to anneke@iitml.\n"
     ]
    }
   ],
   "source": [
    "slack = Slacker('xoxp-554173958562-554173959170-555244937223-1f3cfc06ff8cc48d3a2ea00e6c682a7c')\n",
    "\n",
    "if slack.api.test().successful:\n",
    "    print(\n",
    "        f\"Connected to {slack.team.info().body['team']['name']}.\")\n",
    "else:\n",
    "    print('Try Again!')\n",
    "        \n",
    "def report_stats(text, channel):\n",
    "    \"\"\"Report training stats\"\"\"\n",
    "    r = slack.chat.post_message(channel=channel, text=text,\n",
    "                                username='Code Report',\n",
    "                                icon_emoji=':running:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequence = open_pickle('../../data/imdb/X_tr_sample_original.pkl')\n",
    "X_test_sequence = open_pickle('../../data/imdb/X_te_sample_original.pkl')\n",
    "y_train_target = open_pickle('../../data/imdb/y_tr_target_original.pkl')\n",
    "y_test_target = open_pickle('../../data/imdb/y_te_target_original.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_target[1000:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "GLOVE_DIR = \"../../data/glove.6B/\"\n",
    "GLOVE_DIM = 100\n",
    "\n",
    "def extract_glove_index(file):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, file), 'r')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeddings_index\n",
    "\n",
    "embeddings_index = extract_glove_index('glove.6B.100d.txt')\n",
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 81\n",
    "max_decoder_seq_length = 5\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_sequence)\n",
    "\n",
    "X_tr_padded = pad_sequences(tokenizer.texts_to_sequences(X_train_sequence), maxlen=81, padding='post', truncating='post')\n",
    "y_tr_padded = pad_sequences(tokenizer.texts_to_sequences(y_train_target), maxlen=5, padding='post', truncating='post')\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(X_train_sequence), max_encoder_seq_length, GLOVE_DIM),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(y_train_target), max_decoder_seq_length, GLOVE_DIM),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(y_train_target), max_decoder_seq_length, len(tokenizer.word_index)),\n",
    "    dtype='float32')\n",
    "\n",
    "train_sequence = []\n",
    "target_sequence = []\n",
    "\n",
    "for sample in X_train_sequence:\n",
    "    train_sequence.append(sample.split())\n",
    "for target in y_train_target:\n",
    "    target_sequence.append(target.split())\n",
    "    \n",
    "# 100-dim -> input sequence, input decoder\n",
    "# 42K-dim -> output sequence.\n",
    "\n",
    "for i, (input_text, target_text, target_padded) in enumerate(zip(train_sequence, target_sequence, y_tr_padded)):\n",
    "    for t, word in enumerate(input_text):\n",
    "        try:\n",
    "            encoder_input_data[i, t, :] = embeddings_index[word]\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "    \n",
    "    for t, word in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        try:\n",
    "            decoder_input_data[i, t, :] = embeddings_index[word]\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "        \n",
    "    for t, word in enumerate(target_padded):\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, word] = 1.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34,   78,   38,   40,   12,  375,    1, 4285,  215,    2,    7,\n",
       "        455,    9,   83, 2190,    5,    7,  291,    1,  153,  215,   62,\n",
       "         25,   83,  442,  781,   43,   39,    4,   24,   60,   57,  246,\n",
       "         76,   12,  328,    6,  475,   18,   10,  214,  781,    9,    1,\n",
       "         98,  249,  953,   69,   33,  218,   67,   22,    3,  391,    5,\n",
       "        126, 2220,   83, 4580,  705,  100,   62,   69,   49,  706,  111,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_padded[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 100\n",
    "NUM_ENCODER_TOKENS = np.max(X_tr_padded)\n",
    "NUM_DECODER_TOKENS = np.max(X_tr_padded)\n",
    "max_encoder_seq_length = X_tr_padded.shape[1]\n",
    "max_decoder_seq_length = X_tr_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42406"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DECODER_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42406"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "\n",
    "# encoder_inputs = Input(shape=(None, GLOVE_DIM))\n",
    "# encoder = LSTM(LATENT_DIM, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# decoder_inputs = Input(shape=(None, GLOVE_DIM))\n",
    "# decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                      initial_state=encoder_states)\n",
    "# decoder_dense = Dense(NUM_DECODER_TOKENS, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "model = load_model('100_glove_s2s_overfit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, None, 100)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 100), (None, 80400       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 100),  80400       input_6[0][0]                    \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 42406)  4283006     lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,443,806\n",
      "Trainable params: 4,443,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 500\n",
    "# batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3875\n",
      "Epoch 2/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3360\n",
      "Epoch 3/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2760\n",
      "Epoch 4/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3711\n",
      "Epoch 5/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3251\n",
      "Epoch 6/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2496\n",
      "Epoch 7/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2237\n",
      "Epoch 8/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2100\n",
      "Epoch 9/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2025\n",
      "Epoch 10/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2045\n",
      "Epoch 11/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2000\n",
      "Epoch 12/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1983\n",
      "Epoch 13/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1937\n",
      "Epoch 14/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1992\n",
      "Epoch 15/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2113\n",
      "Epoch 16/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2407\n",
      "Epoch 17/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3554\n",
      "Epoch 18/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3203\n",
      "Epoch 19/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3155\n",
      "Epoch 20/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2475\n",
      "Epoch 21/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2278\n",
      "Epoch 22/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2116\n",
      "Epoch 23/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1937\n",
      "Epoch 24/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1879\n",
      "Epoch 25/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2674\n",
      "Epoch 26/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3328\n",
      "Epoch 27/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2740\n",
      "Epoch 28/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2304\n",
      "Epoch 29/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2139\n",
      "Epoch 30/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2135\n",
      "Epoch 31/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2004\n",
      "Epoch 32/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1952\n",
      "Epoch 33/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1916\n",
      "Epoch 34/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1954\n",
      "Epoch 35/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2015\n",
      "Epoch 36/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2565\n",
      "Epoch 37/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3902\n",
      "Epoch 38/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3598\n",
      "Epoch 39/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3134\n",
      "Epoch 40/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3311\n",
      "Epoch 41/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2634\n",
      "Epoch 42/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2143\n",
      "Epoch 43/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1960\n",
      "Epoch 44/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1935\n",
      "Epoch 45/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1845\n",
      "Epoch 46/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1804\n",
      "Epoch 47/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1832\n",
      "Epoch 48/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1988\n",
      "Epoch 49/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3869\n",
      "Epoch 50/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.3170\n",
      "Epoch 51/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2609\n",
      "Epoch 52/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2254\n",
      "Epoch 53/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2145\n",
      "Epoch 54/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2474\n",
      "Epoch 55/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2013\n",
      "Epoch 56/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1989\n",
      "Epoch 57/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1981\n",
      "Epoch 58/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2080\n",
      "Epoch 59/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2092\n",
      "Epoch 60/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2312\n",
      "Epoch 61/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2412\n",
      "Epoch 62/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2957\n",
      "Epoch 63/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2848\n",
      "Epoch 64/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2704\n",
      "Epoch 65/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2445\n",
      "Epoch 66/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2277\n",
      "Epoch 67/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.4299\n",
      "Epoch 68/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2927\n",
      "Epoch 69/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2250\n",
      "Epoch 70/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1955\n",
      "Epoch 71/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1864\n",
      "Epoch 72/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1792\n",
      "Epoch 73/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1744\n",
      "Epoch 74/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1708\n",
      "Epoch 75/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1916\n",
      "Epoch 76/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2092\n",
      "Epoch 77/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2455\n",
      "Epoch 78/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3042\n",
      "Epoch 79/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3822\n",
      "Epoch 80/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3363\n",
      "Epoch 81/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2461\n",
      "Epoch 82/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2368\n",
      "Epoch 83/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2162\n",
      "Epoch 84/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2008\n",
      "Epoch 85/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1921\n",
      "Epoch 86/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1953\n",
      "Epoch 87/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.4514\n",
      "Epoch 88/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3499\n",
      "Epoch 89/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2456\n",
      "Epoch 90/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2106\n",
      "Epoch 91/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1953\n",
      "Epoch 92/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1842\n",
      "Epoch 93/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2078\n",
      "Epoch 94/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1957\n",
      "Epoch 95/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2052\n",
      "Epoch 96/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2101\n",
      "Epoch 97/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2192\n",
      "Epoch 98/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2041\n",
      "Epoch 99/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2068\n",
      "Epoch 100/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2208\n",
      "Epoch 101/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2532\n",
      "Epoch 102/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2723\n",
      "Epoch 103/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3413\n",
      "Epoch 104/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.4066\n",
      "Epoch 105/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3208\n",
      "Epoch 106/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2393\n",
      "Epoch 107/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2049\n",
      "Epoch 108/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2005\n",
      "Epoch 109/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1999\n",
      "Epoch 110/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1816\n",
      "Epoch 111/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1822\n",
      "Epoch 112/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2130\n",
      "Epoch 113/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.4583\n",
      "Epoch 114/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3147\n",
      "Epoch 115/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2469\n",
      "Epoch 116/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2176\n",
      "Epoch 117/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2068\n",
      "Epoch 118/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1903\n",
      "Epoch 119/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1799\n",
      "Epoch 120/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1684\n",
      "Epoch 121/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1788\n",
      "Epoch 122/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2112\n",
      "Epoch 123/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2068\n",
      "Epoch 124/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2252\n",
      "Epoch 125/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2070\n",
      "Epoch 126/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1957\n",
      "Epoch 127/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1931\n",
      "Epoch 128/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2672\n",
      "Epoch 129/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2946\n",
      "Epoch 130/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.6916\n",
      "Epoch 131/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.5052\n",
      "Epoch 132/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3337\n",
      "Epoch 133/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2801\n",
      "Epoch 134/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3045\n",
      "Epoch 135/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2697\n",
      "Epoch 136/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2219\n",
      "Epoch 137/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2291\n",
      "Epoch 138/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2003\n",
      "Epoch 139/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1846\n",
      "Epoch 140/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1804\n",
      "Epoch 141/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1727\n",
      "Epoch 142/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1695\n",
      "Epoch 143/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1676\n",
      "Epoch 144/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1855\n",
      "Epoch 145/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2553\n",
      "Epoch 146/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2745\n",
      "Epoch 147/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3184\n",
      "Epoch 148/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2713\n",
      "Epoch 149/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2174\n",
      "Epoch 150/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1907\n",
      "Epoch 151/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1811\n",
      "Epoch 152/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1769\n",
      "Epoch 153/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1732\n",
      "Epoch 154/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1682\n",
      "Epoch 155/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1655\n",
      "Epoch 156/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2086\n",
      "Epoch 157/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.9699\n",
      "Epoch 158/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.6360\n",
      "Epoch 159/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.4560\n",
      "Epoch 160/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3970\n",
      "Epoch 161/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3245\n",
      "Epoch 162/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2884\n",
      "Epoch 163/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2664\n",
      "Epoch 164/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2452\n",
      "Epoch 165/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2311\n",
      "Epoch 166/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2257\n",
      "Epoch 167/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2554\n",
      "Epoch 168/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2242\n",
      "Epoch 169/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2117\n",
      "Epoch 170/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2071\n",
      "Epoch 171/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2110\n",
      "Epoch 172/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2030\n",
      "Epoch 173/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1988\n",
      "Epoch 174/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1906\n",
      "Epoch 175/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2031\n",
      "Epoch 176/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2221\n",
      "Epoch 177/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2122\n",
      "Epoch 178/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2012\n",
      "Epoch 179/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3102\n",
      "Epoch 180/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3312\n",
      "Epoch 181/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2711\n",
      "Epoch 182/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2070\n",
      "Epoch 183/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1850\n",
      "Epoch 184/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1828\n",
      "Epoch 185/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1751\n",
      "Epoch 186/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1711\n",
      "Epoch 187/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1723\n",
      "Epoch 188/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1731\n",
      "Epoch 189/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2034\n",
      "Epoch 190/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2457\n",
      "Epoch 191/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2292\n",
      "Epoch 192/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2068\n",
      "Epoch 193/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2132\n",
      "Epoch 194/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2715\n",
      "Epoch 195/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3307\n",
      "Epoch 196/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2443\n",
      "Epoch 197/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2030\n",
      "Epoch 198/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1795\n",
      "Epoch 199/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1764\n",
      "Epoch 200/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1726\n",
      "Epoch 201/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1725\n",
      "Epoch 202/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2932\n",
      "Epoch 203/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3149\n",
      "Epoch 204/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2431\n",
      "Epoch 205/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2193\n",
      "Epoch 206/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1980\n",
      "Epoch 207/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2195\n",
      "Epoch 208/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1851\n",
      "Epoch 209/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1863\n",
      "Epoch 210/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1743\n",
      "Epoch 211/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2786\n",
      "Epoch 212/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2428\n",
      "Epoch 213/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2225\n",
      "Epoch 214/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1961\n",
      "Epoch 215/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2451\n",
      "Epoch 216/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2463\n",
      "Epoch 217/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2194\n",
      "Epoch 218/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2127\n",
      "Epoch 219/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1917\n",
      "Epoch 220/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1888\n",
      "Epoch 221/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2021\n",
      "Epoch 222/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2109\n",
      "Epoch 223/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2344\n",
      "Epoch 224/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2207\n",
      "Epoch 225/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2064\n",
      "Epoch 226/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2114\n",
      "Epoch 227/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1989\n",
      "Epoch 228/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2082\n",
      "Epoch 229/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2044\n",
      "Epoch 230/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2094\n",
      "Epoch 231/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2828\n",
      "Epoch 232/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2848\n",
      "Epoch 233/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2564\n",
      "Epoch 234/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2542\n",
      "Epoch 235/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2436\n",
      "Epoch 236/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2058\n",
      "Epoch 237/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1840\n",
      "Epoch 238/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1798\n",
      "Epoch 239/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1741\n",
      "Epoch 240/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1740\n",
      "Epoch 241/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1809\n",
      "Epoch 242/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1836\n",
      "Epoch 243/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1830\n",
      "Epoch 244/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2456\n",
      "Epoch 245/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2706\n",
      "Epoch 246/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2503\n",
      "Epoch 247/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2784\n",
      "Epoch 248/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2663\n",
      "Epoch 249/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2379\n",
      "Epoch 250/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2408\n",
      "Epoch 251/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1911\n",
      "Epoch 252/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1717\n",
      "Epoch 253/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1619\n",
      "Epoch 254/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1554\n",
      "Epoch 255/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1538\n",
      "Epoch 256/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1519\n",
      "Epoch 257/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1709\n",
      "Epoch 258/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2644\n",
      "Epoch 259/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.4644\n",
      "Epoch 260/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.5047\n",
      "Epoch 261/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.3001\n",
      "Epoch 262/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2308\n",
      "Epoch 263/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1954\n",
      "Epoch 264/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1821\n",
      "Epoch 265/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1803\n",
      "Epoch 266/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1787\n",
      "Epoch 267/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1702\n",
      "Epoch 268/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1592\n",
      "Epoch 269/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1588\n",
      "Epoch 270/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1660\n",
      "Epoch 271/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1917\n",
      "Epoch 272/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2646\n",
      "Epoch 273/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3454\n",
      "Epoch 274/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3242\n",
      "Epoch 275/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2338\n",
      "Epoch 276/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2140\n",
      "Epoch 277/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1894\n",
      "Epoch 278/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1729\n",
      "Epoch 279/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1603\n",
      "Epoch 280/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1549\n",
      "Epoch 281/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1481\n",
      "Epoch 282/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1668\n",
      "Epoch 283/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3995\n",
      "Epoch 284/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3365\n",
      "Epoch 285/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2830\n",
      "Epoch 286/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2557\n",
      "Epoch 287/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2053\n",
      "Epoch 288/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1795\n",
      "Epoch 289/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1638\n",
      "Epoch 290/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1547\n",
      "Epoch 291/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1521\n",
      "Epoch 292/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1486\n",
      "Epoch 293/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1481\n",
      "Epoch 294/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2514\n",
      "Epoch 295/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3351\n",
      "Epoch 296/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3587\n",
      "Epoch 297/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2420\n",
      "Epoch 298/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1958\n",
      "Epoch 299/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1691\n",
      "Epoch 300/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1556\n",
      "Epoch 301/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1508\n",
      "Epoch 302/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1601\n",
      "Epoch 303/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2185\n",
      "Epoch 304/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2490\n",
      "Epoch 305/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.2966\n",
      "Epoch 306/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2534\n",
      "Epoch 307/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2041\n",
      "Epoch 308/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.1870\n",
      "Epoch 309/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1754\n",
      "Epoch 310/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1714\n",
      "Epoch 311/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1836\n",
      "Epoch 312/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1889\n",
      "Epoch 313/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1776\n",
      "Epoch 314/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2026\n",
      "Epoch 315/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2875\n",
      "Epoch 316/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.3512\n",
      "Epoch 317/500\n",
      "22752/22752 [==============================] - 57s 3ms/step - loss: 0.3000\n",
      "Epoch 318/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2590\n",
      "Epoch 319/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2488\n",
      "Epoch 320/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.2136\n",
      "Epoch 321/500\n",
      "22752/22752 [==============================] - 58s 3ms/step - loss: 0.1819\n",
      "Epoch 322/500\n",
      " 3456/22752 [===>..........................] - ETA: 48s - loss: 0.1717"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-830df437169d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "# model.save('100_glove_s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling models\n",
    "\n",
    "# https://nlp.stanford.edu/~johnhew/public/14-seq2seq.pdf\n",
    "# https://medium.com/machine-learning-bites/deeplearning-series-sequence-to-sequence-architectures-4c4ca89e5654\n",
    "\n",
    "model = load_model('100_glove_s2s_overfit.h5')\n",
    "\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,), name='input_3')\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,), name='input_4')\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[3]\n",
    "\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "                    [decoder_inputs] + decoder_states_inputs,\n",
    "                    [decoder_outputs] + decoder_states\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict((i,word) for word,i in word_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_list(X):\n",
    "    y_candidate = []\n",
    "    \n",
    "    for i in range(X.shape[0]-1-5):\n",
    "        y_candidate.append(X[i:i+5])\n",
    "    \n",
    "    return np.asarray(y_candidate)\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "def target_index(doc_idx, candidate_seq, y):\n",
    "    for i,j in enumerate(candidate_seq):\n",
    "        if len(intersection(j, y)) == len(y):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# doc num, doc index argmax\n",
    "\n",
    "def to_sequence(int_sequence):\n",
    "    decoded = ''\n",
    "    for i,intnum in enumerate(int_sequence):\n",
    "        if intnum == 0:\n",
    "            word = '<PAD>'\n",
    "        else:\n",
    "            word = reverse_word_index[intnum]\n",
    "        \n",
    "        if i == len(int_sequence):\n",
    "            decoded += word\n",
    "        else:\n",
    "            decoded += word + ' '\n",
    "    return decoded\n",
    "\n",
    "def rouge_one(true, candidate, start_index):\n",
    "    \n",
    "    if isinstance(true, str) and isinstance(candidate, str):\n",
    "        true = true.split()\n",
    "        candidate = candidate.split()\n",
    "    \n",
    "    overlap = [value for value in true[start_index:] if value in candidate[start_index:]] \n",
    "\n",
    "    \n",
    "    if len(true[start_index:]) != 0:\n",
    "        recall = len(overlap)/len(true[start_index:])\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if len(candidate[start_index:]):\n",
    "        precision = len(overlap)/len(candidate[start_index:])\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if (recall+precision) != 0:    \n",
    "        f1 = 2*((recall*precision)/(recall+precision))\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with candidate\n",
    "\n",
    "def decode_sequence_target(candidate_states_value, candidate_target_seq):\n",
    "#     candidate_states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    from_candidate_target_seq = np.zeros((1,1, GLOVE_DIM))\n",
    "    \n",
    "    candidate_token_index = candidate_target_seq[0,0]\n",
    "    try:\n",
    "        from_candidate_target_seq[0,0,:] = embeddings_index[index_word[candidate_token_index]]\n",
    "    except KeyError as error:\n",
    "        pass\n",
    "    \n",
    "    candidate_joint_log_prob = 0\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        from_candidate_output_tokens, h_true, c_true = decoder_model.predict([from_candidate_target_seq] + candidate_states_value)\n",
    "    \n",
    "        candidate_target_prob = from_candidate_output_tokens[0,-1, candidate_target_seq[0,i]]\n",
    "        candidate_joint_log_prob += np.log(candidate_target_prob)\n",
    "        \n",
    "        # get the t+1 input\n",
    "        \n",
    "        candidate_token_index = candidate_target_seq[0,i]\n",
    "        from_candidate_target_seq = np.zeros((1,1,GLOVE_DIM))\n",
    "        try:\n",
    "            from_candidate_target_seq[0,0,:] = embeddings_index[index_word[candidate_token_index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        candidate_states_value = [h_true, c_true]\n",
    "\n",
    "    return candidate_joint_log_prob, candidate_target_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_list(X):\n",
    "    y_candidate = []\n",
    "    \n",
    "    for i in range(X.shape[0]-1-5):\n",
    "        y_candidate.append(X[i:i+5])\n",
    "    \n",
    "    return np.asarray(y_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the overlap words. \n",
    "t = [0, 5, 6, 7]\n",
    "s = [0, 6, 7, 3]\n",
    "\n",
    "len(intersection(t,s))/len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get overlap here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "# r = Rouge()\n",
    "file = open(\"candidate_jll_glove_100_f1_update.csv\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anneke/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove 100: processing document 0\n",
      "glove 100: processing document 1000\n",
      "glove 100: processing document 2000\n",
      "glove 100: processing document 3000\n",
      "glove 100: processing document 4000\n",
      "glove 100: processing document 5000\n",
      "glove 100: processing document 6000\n",
      "glove 100: processing document 7000\n",
      "glove 100: processing document 8000\n",
      "glove 100: processing document 9000\n",
      "glove 100: processing document 10000\n",
      "glove 100: processing document 11000\n",
      "glove 100: processing document 12000\n",
      "glove 100: processing document 13000\n",
      "glove 100: processing document 14000\n",
      "glove 100: processing document 15000\n",
      "glove 100: processing document 16000\n",
      "glove 100: processing document 17000\n",
      "glove 100: processing document 18000\n",
      "glove 100: processing document 19000\n",
      "glove 100: processing document 20000\n",
      "glove 100: processing document 21000\n",
      "glove 100: processing document 22000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 42406 is out of bounds for axis 2 with size 42406",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-974883033a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_candidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcandidate_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_last_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcandidate_jll_per_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-37055bc58994>\u001b[0m in \u001b[0;36mdecode_sequence_target\u001b[0;34m(candidate_states_value, candidate_target_seq)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrom_candidate_target_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcandidate_target_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcandidate_joint_log_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_target_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 42406 is out of bounds for axis 2 with size 42406"
     ]
    }
   ],
   "source": [
    "for doc in X_tr_padded:\n",
    "    y_candidate = generate_candidate_list(doc)\n",
    "    \n",
    "    candidate_jll_per_doc = []\n",
    "    input_seq = encoder_input_data[i:i+1]\n",
    "    \n",
    "    true_target_index = target_index(i, y_candidate, y_tr_padded[i])\n",
    "#     print(y_candidate)\n",
    "    # Encode\n",
    "    candidate_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    for j in range(y_candidate.shape[0]):\n",
    "        candidate_seq = y_candidate[j:j+1]\n",
    "        candidate_jll_slide, candidate_last_prob = decode_sequence_target(candidate_states_value, candidate_seq)\n",
    "        candidate_jll_per_doc.append(candidate_jll_slide)\n",
    "\n",
    "    candidate_jll_per_doc = np.asarray(candidate_jll_per_doc)\n",
    "    max_jll_index = np.argmax(candidate_jll_per_doc)\n",
    "    true_target_jll = np.around(candidate_jll_per_doc[true_target_index],5)\n",
    "    max_candidate_jll = np.around(candidate_jll_per_doc[max_jll_index],5)\n",
    "    \n",
    "    # get recall here\n",
    "    [precision, recall, f_score] = rouge_one(y_train_target[i], to_sequence(y_candidate[max_jll_index]), 1)\n",
    "    \n",
    "    file.write('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\n' %(i, true_target_index, y_train_target[i],\n",
    "                                                            max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "                                                            -(true_target_index-max_jll_index),\n",
    "                                                            true_target_jll, max_candidate_jll,\n",
    "                                                            np.absolute(true_target_jll-max_candidate_jll),\n",
    "                                                            len(intersection(y_tr_padded[i], y_candidate[max_jll_index])),\n",
    "                                                            np.exp(true_target_jll/4), np.exp(max_candidate_jll/4),\n",
    "                                                            precision, recall, f_score))\n",
    "    \n",
    "#     print('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\n' %(i, true_target_index, y['text'][i],\n",
    "#                                                             max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "#                                                             -(true_target_index-max_jll_index),\n",
    "#                                                             true_target_jll, max_candidate_jll,\n",
    "#                                                             np.absolute(true_target_jll-max_candidate_jll),\n",
    "#                                                             len(intersection(y['padded'][i], y_candidate[max_jll_index]))))\n",
    "\n",
    "#     print('%s\\t%s\\t%.1f\\n' %(y_train_target[i], to_sequence(y_candidate[max_jll_index]), precision, recall))\n",
    "    if i % 1000 == 0:\n",
    "#         print('Processing document %d...' %(i))\n",
    "        msg = 'glove 100: processing document ' + str(i)\n",
    "        report_stats(msg, 'deep-learning')\n",
    "        print(msg)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "file.close()\n",
    "report_stats('Processing DONE', 'deep-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import CSVLogger\n",
    "\n",
    "# csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start test data preprocessing\n",
    "\n",
    "# X_te = open_pickle('../../data/imdb_sequence/3000_one_hot/X_te_seq_set.pkl')\n",
    "# y_te = open_pickle('../../data/imdb_sequence/3000_one_hot/y_te_seq_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 81\n",
    "max_decoder_seq_length = 5\n",
    "\n",
    "X_te_padded = pad_sequences(tokenizer.texts_to_sequences(X_test_sequence), maxlen=81, padding='post', truncating='post')\n",
    "y_te_padded = pad_sequences(tokenizer.texts_to_sequences(y_test_target), maxlen=5, padding='post', truncating='post')\n",
    "\n",
    "test_encoder_input_data = np.zeros(\n",
    "    (len(X_test_sequence), max_encoder_seq_length, GLOVE_DIM),\n",
    "    dtype='float32')\n",
    "test_decoder_input_data = np.zeros(\n",
    "    (len(y_test_target), max_decoder_seq_length, GLOVE_DIM),\n",
    "    dtype='float32')\n",
    "test_decoder_target_data = np.zeros(\n",
    "    (len(y_test_target), max_decoder_seq_length, len(tokenizer.word_index)),\n",
    "    dtype='float32')\n",
    "\n",
    "test_sequence = []\n",
    "test_target_sequence = []\n",
    "\n",
    "for sample in X_test_sequence:\n",
    "    test_sequence.append(sample.split())\n",
    "for target in y_test_target:\n",
    "    test_target_sequence.append(target.split())\n",
    "    \n",
    "# 100-dim -> input sequence, input decoder\n",
    "# 42K-dim -> output sequence.\n",
    "\n",
    "for i, (input_text, target_text, target_padded) in enumerate(zip(test_sequence, test_target_sequence, y_tr_padded)):\n",
    "    for t, word in enumerate(input_text):\n",
    "        try:\n",
    "            test_encoder_input_data[i, t, :] = embeddings_index[word]\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "    \n",
    "    for t, word in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        try:\n",
    "            test_decoder_input_data[i, t, :] = embeddings_index[word]\n",
    "        except KeyError as error:\n",
    "            continue\n",
    "        \n",
    "    for t, word in enumerate(target_padded):\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            test_decoder_target_data[i, t - 1, word] = 1.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with candidate\n",
    "\n",
    "def test_decode_sequence_target(candidate_states_value, candidate_target_seq):\n",
    "#     candidate_states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    from_candidate_target_seq = np.zeros((1,1, GLOVE_DIM))\n",
    "    \n",
    "    candidate_token_index = candidate_target_seq[0,0]\n",
    "    try:\n",
    "        from_candidate_target_seq[0,0,:] = embeddings_index[index_word[candidate_token_index]]\n",
    "    except KeyError as error:\n",
    "        pass\n",
    "    \n",
    "    candidate_joint_log_prob = 0\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        from_candidate_output_tokens, h_true, c_true = decoder_model.predict([from_candidate_target_seq] + candidate_states_value)\n",
    "    \n",
    "        candidate_target_prob = from_candidate_output_tokens[0,-1, candidate_target_seq[0,i]]\n",
    "        candidate_joint_log_prob += np.log(candidate_target_prob)\n",
    "        \n",
    "        # get the t+1 input\n",
    "        \n",
    "        candidate_token_index = candidate_target_seq[0,i]\n",
    "        from_candidate_target_seq = np.zeros((1,1,GLOVE_DIM))\n",
    "        try:\n",
    "            from_candidate_target_seq[0,0,:] = embeddings_index[index_word[candidate_token_index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        candidate_states_value = [h_true, c_true]\n",
    "\n",
    "    return candidate_joint_log_prob, candidate_target_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 15380\n",
    "# start = 15380\n",
    "file = open(\"test_candidate_jll_glove_100_f1_update.csv\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anneke/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove 100 test: processing document 0\n",
      "glove 100 test: processing document 1000\n",
      "glove 100 test: processing document 2000\n",
      "glove 100 test: processing document 3000\n",
      "glove 100 test: processing document 4000\n",
      "glove 100 test: processing document 5000\n",
      "glove 100 test: processing document 6000\n",
      "glove 100 test: processing document 7000\n",
      "glove 100 test: processing document 8000\n",
      "glove 100 test: processing document 9000\n",
      "glove 100 test: processing document 10000\n",
      "glove 100 test: processing document 11000\n",
      "glove 100 test: processing document 12000\n",
      "glove 100 test: processing document 13000\n",
      "glove 100 test: processing document 14000\n",
      "glove 100 test: processing document 15000\n",
      "glove 100 test: processing document 16000\n",
      "glove 100 test: processing document 17000\n",
      "glove 100 test: processing document 18000\n",
      "glove 100 test: processing document 19000\n",
      "glove 100 test: processing document 20000\n",
      "glove 100 test: processing document 21000\n",
      "glove 100 test: processing document 22000\n"
     ]
    }
   ],
   "source": [
    "for i,doc in enumerate(X_te_padded):\n",
    "    y_candidate = generate_candidate_list(doc)\n",
    "    \n",
    "    candidate_jll_per_doc = []\n",
    "    input_seq = test_encoder_input_data[i:i+1]\n",
    "    \n",
    "    true_target_index = target_index(i, y_candidate, y_te_padded[i])\n",
    "    \n",
    "    # Encode\n",
    "    candidate_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    for j in range(y_candidate.shape[0]):\n",
    "        candidate_seq = y_candidate[j:j+1]\n",
    "        candidate_jll_slide, candidate_last_prob = test_decode_sequence_target(candidate_states_value, candidate_seq)\n",
    "        candidate_jll_per_doc.append(candidate_jll_slide)\n",
    "   \n",
    "    candidate_jll_per_doc = np.asarray(candidate_jll_per_doc)\n",
    "    max_jll_index = np.argmax(candidate_jll_per_doc)\n",
    "    true_target_jll = np.around(candidate_jll_per_doc[true_target_index],5)\n",
    "    max_candidate_jll = np.around(candidate_jll_per_doc[max_jll_index],5)\n",
    "    \n",
    "    [precision, recall, f_score] = rouge_one(y_test_target[i], to_sequence(y_candidate[max_jll_index]), 1)\n",
    "    \n",
    "    file.write('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\n' %(i, true_target_index, y_test_target[i],\n",
    "                                                            max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "                                                            -(true_target_index-max_jll_index),\n",
    "                                                            true_target_jll, max_candidate_jll,\n",
    "                                                            np.absolute(true_target_jll-max_candidate_jll),\n",
    "                                                            len(intersection(y_te_padded[i], y_candidate[max_jll_index])),\n",
    "                                                            np.exp(true_target_jll/4), np.exp(max_candidate_jll/4),\n",
    "                                                            precision, recall, f_score))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#     print('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\n' %(i, true_target_index, y['text'][i],\n",
    "#                                                             max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "#                                                             -(true_target_index-max_jll_index),\n",
    "#                                                             true_target_jll, max_candidate_jll,\n",
    "#                                                             np.absolute(true_target_jll-max_candidate_jll),\n",
    "#                                                             len(intersection(y['padded'][i], y_candidate[max_jll_index]))))\n",
    "    if i % 1000 == 0:\n",
    "#         print('Processing document %d...' %(i))\n",
    "        msg = 'glove 100 test: processing document ' + str(i)\n",
    "        report_stats(msg, 'deep-learning')\n",
    "        print(msg)\n",
    "        \n",
    "#     i += 1\n",
    "    \n",
    "file.close()\n",
    "report_stats('Processing DONE', 'deep-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
