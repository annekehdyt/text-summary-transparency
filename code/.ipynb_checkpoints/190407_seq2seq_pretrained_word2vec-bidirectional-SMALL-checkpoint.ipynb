{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17984127049868687444\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional\n",
    "\n",
    "https://stackoverflow.com/questions/47923370/keras-bidirectional-lstm-seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import gensim\n",
    "import keras as k\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "import util as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto(device_count={\"CPU\": 8})\n",
    "# k.backend.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Slacker Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to anneke@iitml.\n"
     ]
    }
   ],
   "source": [
    "slack = u.initiate_slacker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Google's pretrained word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('../../data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequence = u.open_pickle('../../data/imdb/X_tr_sample_original.pkl')\n",
    "X_test_sequence = u.open_pickle('../../data/imdb/X_te_sample_original.pkl')\n",
    "y_train_target = u.open_pickle('../../data/imdb/y_tr_target_original.pkl')\n",
    "y_test_target = u.open_pickle('../../data/imdb/y_te_target_original.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_target = [' '.join(['UNK', y]) for y in y_train_target]\n",
    "y_test_target = [' '.join(['UNK', y]) for y in y_test_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNK was an excellent show it'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize constant here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ENCODER_SEQ_LEN = 81\n",
    "MAX_DECODER_SEQ_LEN = 6 #include <UNK>\n",
    "EMBEDDING_DIM = 300\n",
    "LATENT_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the train sequence data\n",
    "tokenizer = k.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_sequence)\n",
    "\n",
    "# Generate text to integer sequence with post padding\n",
    "X_tr_padded = pad_sequences(tokenizer.texts_to_sequences(X_train_sequence), maxlen=MAX_ENCODER_SEQ_LEN, padding='post', truncating='post')\n",
    "y_tr_padded = pad_sequences(tokenizer.texts_to_sequences(y_train_target), maxlen=MAX_DECODER_SEQ_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   60,   241,     5,     3,   716,   258,     5,   439, 23995,\n",
       "           3,  1087,    65,    36,   129,   408,    17,    12,    79,\n",
       "           5,    24,   181,  1544, 12813,     4,   625,     2,  1720,\n",
       "        1253,   695,    30,    46,   479,   264,   200,    17,    12,\n",
       "         208,     6,    98,    10,    56,     3,   167, 10118,    36,\n",
       "         129,   408,    21,  2757,   227,   101,    32,  3166,  2188,\n",
       "           2, 23996,  2189,    17,    11,    82,    12,    61,    98,\n",
       "         108,  1440,   515,     8,   160,    22,   301,     1,   202,\n",
       "         184,    50,     5,    57,  1501,   160,    43,     8,    81],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DECODER_TOKENS = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42406"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DECODER_TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the container for input sequence decoder and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(X_train_sequence), MAX_ENCODER_SEQ_LEN, EMBEDDING_DIM),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(y_train_target), MAX_DECODER_SEQ_LEN, EMBEDDING_DIM),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(y_train_target), MAX_DECODER_SEQ_LEN, len(tokenizer.word_index)),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {v: k for k, v in tokenizer.word_index.items()}\n",
    "index_to_word[0] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_sequence, target_sequence) in enumerate(zip(X_tr_padded, y_tr_padded)):\n",
    "    # embed the input sequence\n",
    "    for t, index in enumerate(input_sequence):\n",
    "        try:\n",
    "            encoder_input_data[i, t, :] = w2v_model[index_to_word[index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "    \n",
    "    # embed the input decoder\n",
    "    for t, index in enumerate(target_sequence):\n",
    "        try:\n",
    "            decoder_input_data[i, t, :] = w2v_model[index_to_word[index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "    for t, index in enumerate(target_sequence):\n",
    "        # not include the first <UNK>\n",
    "        if t>0:\n",
    "            decoder_target_data[i, t - 1, index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = k.callbacks.ModelCheckpoint(save_best_only=True, monitor='val_loss', filepath='./300_word2vec_bidirectional_SMALL_best_model/weights.{epoch:04d}-{val_loss:.3f}.h5')\n",
    "# csvlogger = k.callbacks.CSVLogger(filename='word2vec_300_bidirectional_SMALL_history.log', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = k.layers.Input(shape=(None, EMBEDDING_DIM))\n",
    "# encoder = k.layers.Bidirectional(LSTM(int(LATENT_DIM/2), return_state=True))\n",
    "# # encoder_outputs, state_h, state_c = encoder(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "\n",
    "# state_h = k.layers.Concatenate()([forward_h, backward_h])\n",
    "# state_c = k.layers.Concatenate()([forward_c, backward_c])\n",
    "# encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_inputs = k.layers.Input(shape=(None, EMBEDDING_DIM))\n",
    "# decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                     initial_state=encoder_states)\n",
    "\n",
    "# decoder_dense = k.layers.Dense(NUM_DECODER_TOKENS, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model = k.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# train_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=200\n",
    "# batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15168 samples, validate on 7584 samples\n",
      "Epoch 1/200\n",
      "15168/15168 [==============================] - 436s 29ms/step - loss: 6.4019 - val_loss: 4.3402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anneke/.local/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_7 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'concatenate_1/concat:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "15168/15168 [==============================] - 433s 29ms/step - loss: 4.1536 - val_loss: 4.2050\n",
      "Epoch 3/200\n",
      "15168/15168 [==============================] - 432s 28ms/step - loss: 4.0481 - val_loss: 4.1522\n",
      "Epoch 4/200\n",
      "15168/15168 [==============================] - 434s 29ms/step - loss: 3.9852 - val_loss: 4.1172\n",
      "Epoch 5/200\n",
      "15168/15168 [==============================] - 433s 29ms/step - loss: 3.9395 - val_loss: 4.0909\n",
      "Epoch 6/200\n",
      "15168/15168 [==============================] - 431s 28ms/step - loss: 3.9035 - val_loss: 4.0680\n",
      "Epoch 7/200\n",
      "15168/15168 [==============================] - 432s 28ms/step - loss: 3.8724 - val_loss: 4.0490\n",
      "Epoch 8/200\n",
      "15168/15168 [==============================] - 430s 28ms/step - loss: 3.8454 - val_loss: 4.0281\n",
      "Epoch 9/200\n",
      "15168/15168 [==============================] - 430s 28ms/step - loss: 3.8144 - val_loss: 3.9963\n",
      "Epoch 10/200\n",
      "15168/15168 [==============================] - 430s 28ms/step - loss: 3.7756 - val_loss: 3.9580\n",
      "Epoch 11/200\n",
      "15168/15168 [==============================] - 431s 28ms/step - loss: 3.7338 - val_loss: 3.9129\n",
      "Epoch 12/200\n",
      "15168/15168 [==============================] - 430s 28ms/step - loss: 3.6854 - val_loss: 3.8642\n",
      "Epoch 13/200\n",
      "15168/15168 [==============================] - 430s 28ms/step - loss: 3.6325 - val_loss: 3.8136\n",
      "Epoch 14/200\n",
      "15168/15168 [==============================] - 430s 28ms/step - loss: 3.5862 - val_loss: 3.7772\n",
      "Epoch 15/200\n",
      "15168/15168 [==============================] - 430s 28ms/step - loss: 3.5471 - val_loss: 3.7424\n",
      "Epoch 16/200\n",
      "15168/15168 [==============================] - 430s 28ms/step - loss: 3.5127 - val_loss: 3.7107\n",
      "Epoch 17/200\n",
      "15168/15168 [==============================] - 436s 29ms/step - loss: 3.4822 - val_loss: 3.6858\n",
      "Epoch 18/200\n",
      "15168/15168 [==============================] - 426s 28ms/step - loss: 3.4538 - val_loss: 3.6617\n",
      "Epoch 19/200\n",
      "15168/15168 [==============================] - 399s 26ms/step - loss: 3.4271 - val_loss: 3.6373\n",
      "Epoch 20/200\n",
      "15168/15168 [==============================] - 399s 26ms/step - loss: 3.4025 - val_loss: 3.6218\n",
      "Epoch 21/200\n",
      "15168/15168 [==============================] - 397s 26ms/step - loss: 3.3799 - val_loss: 3.5999\n",
      "Epoch 22/200\n",
      "15168/15168 [==============================] - 400s 26ms/step - loss: 3.3554 - val_loss: 3.5817\n",
      "Epoch 23/200\n",
      "15168/15168 [==============================] - 400s 26ms/step - loss: 3.3313 - val_loss: 3.5573\n",
      "Epoch 24/200\n",
      "15168/15168 [==============================] - 399s 26ms/step - loss: 3.3044 - val_loss: 3.5366\n",
      "Epoch 25/200\n",
      "15168/15168 [==============================] - 399s 26ms/step - loss: 3.2749 - val_loss: 3.5064\n",
      "Epoch 26/200\n",
      "15168/15168 [==============================] - 401s 26ms/step - loss: 3.2437 - val_loss: 3.4775\n",
      "Epoch 27/200\n",
      "15168/15168 [==============================] - 400s 26ms/step - loss: 3.2110 - val_loss: 3.4521\n",
      "Epoch 28/200\n",
      "15168/15168 [==============================] - 415s 27ms/step - loss: 3.1816 - val_loss: 3.4259\n",
      "Epoch 29/200\n",
      "15168/15168 [==============================] - 431s 28ms/step - loss: 3.1506 - val_loss: 3.4062\n",
      "Epoch 30/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 3.1247 - val_loss: 3.3835\n",
      "Epoch 31/200\n",
      "15168/15168 [==============================] - 468s 31ms/step - loss: 3.0994 - val_loss: 3.3654\n",
      "Epoch 32/200\n",
      "15168/15168 [==============================] - 452s 30ms/step - loss: 3.0708 - val_loss: 3.3403\n",
      "Epoch 33/200\n",
      "15168/15168 [==============================] - 453s 30ms/step - loss: 3.0359 - val_loss: 3.3065\n",
      "Epoch 34/200\n",
      "15168/15168 [==============================] - 453s 30ms/step - loss: 3.0000 - val_loss: 3.2809\n",
      "Epoch 35/200\n",
      "15168/15168 [==============================] - 452s 30ms/step - loss: 2.9635 - val_loss: 3.2567\n",
      "Epoch 36/200\n",
      "15168/15168 [==============================] - 451s 30ms/step - loss: 2.9298 - val_loss: 3.2271\n",
      "Epoch 37/200\n",
      "15168/15168 [==============================] - 450s 30ms/step - loss: 2.8981 - val_loss: 3.2009\n",
      "Epoch 38/200\n",
      "15168/15168 [==============================] - 451s 30ms/step - loss: 2.8675 - val_loss: 3.1846\n",
      "Epoch 39/200\n",
      "15168/15168 [==============================] - 452s 30ms/step - loss: 2.8400 - val_loss: 3.1655\n",
      "Epoch 40/200\n",
      "15168/15168 [==============================] - 452s 30ms/step - loss: 2.8121 - val_loss: 3.1393\n",
      "Epoch 41/200\n",
      "15168/15168 [==============================] - 476s 31ms/step - loss: 2.7838 - val_loss: 3.1184\n",
      "Epoch 42/200\n",
      "15168/15168 [==============================] - 455s 30ms/step - loss: 2.7561 - val_loss: 3.1068\n",
      "Epoch 43/200\n",
      "15168/15168 [==============================] - 456s 30ms/step - loss: 2.7324 - val_loss: 3.0788\n",
      "Epoch 44/200\n",
      "15168/15168 [==============================] - 455s 30ms/step - loss: 2.7023 - val_loss: 3.0648\n",
      "Epoch 45/200\n",
      "15168/15168 [==============================] - 455s 30ms/step - loss: 2.6796 - val_loss: 3.0458\n",
      "Epoch 46/200\n",
      "15168/15168 [==============================] - 452s 30ms/step - loss: 2.6523 - val_loss: 3.0304\n",
      "Epoch 47/200\n",
      "15168/15168 [==============================] - 450s 30ms/step - loss: 2.6239 - val_loss: 3.0086\n",
      "Epoch 48/200\n",
      "15168/15168 [==============================] - 451s 30ms/step - loss: 2.5967 - val_loss: 2.9932\n",
      "Epoch 49/200\n",
      "15168/15168 [==============================] - 450s 30ms/step - loss: 2.5708 - val_loss: 2.9778\n",
      "Epoch 50/200\n",
      "15168/15168 [==============================] - 450s 30ms/step - loss: 2.5446 - val_loss: 2.9620\n",
      "Epoch 51/200\n",
      "15168/15168 [==============================] - 450s 30ms/step - loss: 2.5176 - val_loss: 2.9459\n",
      "Epoch 52/200\n",
      "15168/15168 [==============================] - 451s 30ms/step - loss: 2.4939 - val_loss: 2.9309\n",
      "Epoch 53/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.4709 - val_loss: 2.9253\n",
      "Epoch 54/200\n",
      "15168/15168 [==============================] - 450s 30ms/step - loss: 2.4484 - val_loss: 2.9126\n",
      "Epoch 55/200\n",
      "15168/15168 [==============================] - 452s 30ms/step - loss: 2.4249 - val_loss: 2.9021\n",
      "Epoch 56/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.4035 - val_loss: 2.8883\n",
      "Epoch 57/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.3833 - val_loss: 2.8822\n",
      "Epoch 58/200\n",
      "15168/15168 [==============================] - 451s 30ms/step - loss: 2.3598 - val_loss: 2.8663\n",
      "Epoch 59/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.3392 - val_loss: 2.8596\n",
      "Epoch 60/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 2.3186 - val_loss: 2.8490\n",
      "Epoch 61/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.2938 - val_loss: 2.8372\n",
      "Epoch 62/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.2764 - val_loss: 2.8261\n",
      "Epoch 63/200\n",
      "15168/15168 [==============================] - 447s 29ms/step - loss: 2.2538 - val_loss: 2.8171\n",
      "Epoch 64/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.2325 - val_loss: 2.8112\n",
      "Epoch 65/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 2.2118 - val_loss: 2.8000\n",
      "Epoch 66/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.1886 - val_loss: 2.7945\n",
      "Epoch 67/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 2.1693 - val_loss: 2.7889\n",
      "Epoch 68/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 2.1481 - val_loss: 2.7780\n",
      "Epoch 69/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 2.1291 - val_loss: 2.7733\n",
      "Epoch 70/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 2.1122 - val_loss: 2.7679\n",
      "Epoch 71/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.0921 - val_loss: 2.7592\n",
      "Epoch 72/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.0719 - val_loss: 2.7612\n",
      "Epoch 73/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.0541 - val_loss: 2.7540\n",
      "Epoch 74/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 2.0355 - val_loss: 2.7436\n",
      "Epoch 75/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 2.0183 - val_loss: 2.7498\n",
      "Epoch 76/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 2.0016 - val_loss: 2.7421\n",
      "Epoch 77/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.9828 - val_loss: 2.7288\n",
      "Epoch 78/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.9660 - val_loss: 2.7311\n",
      "Epoch 79/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.9468 - val_loss: 2.7249\n",
      "Epoch 80/200\n",
      "15168/15168 [==============================] - 447s 29ms/step - loss: 1.9296 - val_loss: 2.7237\n",
      "Epoch 81/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.9140 - val_loss: 2.7201\n",
      "Epoch 82/200\n",
      "15168/15168 [==============================] - 447s 29ms/step - loss: 1.8999 - val_loss: 2.7239\n",
      "Epoch 83/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 1.8812 - val_loss: 2.7158\n",
      "Epoch 84/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.8627 - val_loss: 2.7165\n",
      "Epoch 85/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.8477 - val_loss: 2.7102\n",
      "Epoch 86/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.8298 - val_loss: 2.7072\n",
      "Epoch 87/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.8149 - val_loss: 2.7069\n",
      "Epoch 88/200\n",
      "15168/15168 [==============================] - 447s 29ms/step - loss: 1.7987 - val_loss: 2.7016\n",
      "Epoch 89/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.7834 - val_loss: 2.7038\n",
      "Epoch 90/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.7690 - val_loss: 2.6994\n",
      "Epoch 91/200\n",
      "15168/15168 [==============================] - 447s 29ms/step - loss: 1.7536 - val_loss: 2.7014\n",
      "Epoch 92/200\n",
      "15168/15168 [==============================] - 447s 29ms/step - loss: 1.7381 - val_loss: 2.7052\n",
      "Epoch 93/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.7241 - val_loss: 2.7013\n",
      "Epoch 94/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.7057 - val_loss: 2.7005\n",
      "Epoch 95/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.6917 - val_loss: 2.7026\n",
      "Epoch 96/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.6763 - val_loss: 2.7094\n",
      "Epoch 97/200\n",
      "15168/15168 [==============================] - 449s 30ms/step - loss: 1.6651 - val_loss: 2.6978\n",
      "Epoch 98/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.6490 - val_loss: 2.7027\n",
      "Epoch 99/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.6396 - val_loss: 2.6959\n",
      "Epoch 100/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.6209 - val_loss: 2.7046\n",
      "Epoch 101/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.6051 - val_loss: 2.7107\n",
      "Epoch 102/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.5914 - val_loss: 2.7057\n",
      "Epoch 103/200\n",
      "15168/15168 [==============================] - 448s 30ms/step - loss: 1.5776 - val_loss: 2.7098\n",
      "Epoch 104/200\n",
      "15168/15168 [==============================] - 447s 29ms/step - loss: 1.5678 - val_loss: 2.7081\n",
      "Epoch 105/200\n",
      "15168/15168 [==============================] - 446s 29ms/step - loss: 1.5518 - val_loss: 2.7119\n",
      "Epoch 106/200\n",
      "15168/15168 [==============================] - 435s 29ms/step - loss: 1.5381 - val_loss: 2.7169\n",
      "Epoch 107/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.5259 - val_loss: 2.7144\n",
      "Epoch 108/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.5118 - val_loss: 2.7156\n",
      "Epoch 109/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.4971 - val_loss: 2.7134\n",
      "Epoch 110/200\n",
      "15168/15168 [==============================] - 412s 27ms/step - loss: 1.4844 - val_loss: 2.7207\n",
      "Epoch 111/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.4730 - val_loss: 2.7242\n",
      "Epoch 112/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.4632 - val_loss: 2.7306\n",
      "Epoch 113/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.4508 - val_loss: 2.7234\n",
      "Epoch 114/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.4342 - val_loss: 2.7303\n",
      "Epoch 115/200\n",
      "15168/15168 [==============================] - 412s 27ms/step - loss: 1.4227 - val_loss: 2.7406\n",
      "Epoch 116/200\n",
      "15168/15168 [==============================] - 412s 27ms/step - loss: 1.4100 - val_loss: 2.7400\n",
      "Epoch 117/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.3984 - val_loss: 2.7347\n",
      "Epoch 118/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.3833 - val_loss: 2.7400\n",
      "Epoch 119/200\n",
      "15168/15168 [==============================] - 413s 27ms/step - loss: 1.3722 - val_loss: 2.7459\n",
      "Epoch 120/200\n",
      "15168/15168 [==============================] - 415s 27ms/step - loss: 1.3622 - val_loss: 2.7478\n",
      "Epoch 121/200\n",
      "15168/15168 [==============================] - 416s 27ms/step - loss: 1.3517 - val_loss: 2.7577\n",
      "Epoch 122/200\n",
      "15168/15168 [==============================] - 414s 27ms/step - loss: 1.3424 - val_loss: 2.7586\n",
      "Epoch 123/200\n",
      "15168/15168 [==============================] - 415s 27ms/step - loss: 1.3369 - val_loss: 2.7527\n",
      "Epoch 124/200\n",
      "15168/15168 [==============================] - 413s 27ms/step - loss: 1.3178 - val_loss: 2.7625\n",
      "Epoch 125/200\n",
      "15168/15168 [==============================] - 414s 27ms/step - loss: 1.3043 - val_loss: 2.7616\n",
      "Epoch 126/200\n",
      "15168/15168 [==============================] - 414s 27ms/step - loss: 1.2964 - val_loss: 2.7732\n",
      "Epoch 127/200\n",
      "15168/15168 [==============================] - 414s 27ms/step - loss: 1.2859 - val_loss: 2.7640\n",
      "Epoch 128/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.2751 - val_loss: 2.7754\n",
      "Epoch 129/200\n",
      "15168/15168 [==============================] - 411s 27ms/step - loss: 1.2645 - val_loss: 2.7742\n",
      "Epoch 130/200\n",
      "15168/15168 [==============================] - 412s 27ms/step - loss: 1.2534 - val_loss: 2.7735\n",
      "Epoch 131/200\n",
      "15168/15168 [==============================] - 412s 27ms/step - loss: 1.2449 - val_loss: 2.7821\n",
      "Epoch 132/200\n",
      " 1536/15168 [==>...........................] - ETA: 5:48 - loss: 1.2152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e1e042139303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           verbose=1, callbacks=[checkpoint, csvlogger])\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_split=(1./3),\n",
    "#           verbose=1, callbacks=[checkpoint, csvlogger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) [(None, 100), (None, 140400      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100)          0           bidirectional_6[0][1]            \n",
      "                                                                 bidirectional_6[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100)          0           bidirectional_6[0][2]            \n",
      "                                                                 bidirectional_6[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 100),  160400      input_7[0][0]                    \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 42406)  4283006     lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,583,806\n",
      "Trainable params: 4,583,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./300_word2vec_bidirectional_SMALL_best_model/weights.0099-2.696.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.input[0]\n",
    "\n",
    "\n",
    "encoder_outputs, forward_state_h_enc, forward_state_c_enc, backward_state_h_enc, backward_state_c_enc = model.layers[1].output\n",
    "state_h_enc = k.layers.Concatenate()([forward_state_h_enc, backward_state_h_enc])\n",
    "state_c_enc = k.layers.Concatenate()([forward_state_c_enc, backward_state_c_enc])\n",
    "\n",
    "# state_h_end = k.layers[]\n",
    "\n",
    "\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,), name='input_5')\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,), name='input_6')\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[5]\n",
    "\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[6]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "                    [decoder_inputs] + decoder_states_inputs,\n",
    "                    [decoder_outputs] + decoder_states\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict((i,word) for word,i in word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_list(X):\n",
    "    y_candidate = []\n",
    "    \n",
    "    for i in range(X.shape[0]-1-5):\n",
    "        y_candidate.append(X[i:i+5])\n",
    "    \n",
    "    return np.asarray(y_candidate)\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "def target_index(doc_idx, candidate_seq, y):\n",
    "    for i,j in enumerate(candidate_seq):\n",
    "        if len(intersection(j, y)) == len(y):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# doc num, doc index argmax\n",
    "\n",
    "def to_sequence(int_sequence):\n",
    "    decoded = ''\n",
    "    for i,intnum in enumerate(int_sequence):\n",
    "        if intnum == 0:\n",
    "            word = '<PAD>'\n",
    "        else:\n",
    "            word = reverse_word_index[intnum]\n",
    "        \n",
    "        if i == len(int_sequence):\n",
    "            decoded += word\n",
    "        else:\n",
    "            decoded += word + ' '\n",
    "    return decoded\n",
    "\n",
    "def rouge_one(true, candidate, start_index):\n",
    "    \n",
    "    if isinstance(true, str) and isinstance(candidate, str):\n",
    "        true = true.split()\n",
    "        candidate = candidate.split()\n",
    "    \n",
    "    overlap = [value for value in true[start_index:] if value in candidate[start_index:]] \n",
    "\n",
    "    \n",
    "    if len(true[start_index:]) != 0:\n",
    "        recall = len(overlap)/len(true[start_index:])\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if len(candidate[start_index:]):\n",
    "        precision = len(overlap)/len(candidate[start_index:])\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if (recall+precision) != 0:    \n",
    "        f1 = 2*((recall*precision)/(recall+precision))\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with candidate\n",
    "\n",
    "def decode_sequence_target(candidate_states_value, candidate_target_seq):\n",
    "#     candidate_states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    from_candidate_target_seq = np.zeros((1,1, EMBEDDING_DIM))\n",
    "    \n",
    "    candidate_token_index = candidate_target_seq[0,0]\n",
    "    try:\n",
    "        from_candidate_target_seq[0,0,:] = w2v_model[index_to_word[candidate_token_index]]\n",
    "    except KeyError as error:\n",
    "        pass\n",
    "    \n",
    "    candidate_joint_log_prob = 0\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        from_candidate_output_tokens, h_true, c_true = decoder_model.predict([from_candidate_target_seq] + candidate_states_value)\n",
    "    \n",
    "        candidate_target_prob = from_candidate_output_tokens[0,-1, candidate_target_seq[0,i]]\n",
    "        candidate_joint_log_prob += np.log(candidate_target_prob)\n",
    "        \n",
    "        # get the t+1 input\n",
    "        \n",
    "        candidate_token_index = candidate_target_seq[0,i]\n",
    "        from_candidate_target_seq = np.zeros((1,1,EMBEDDING_DIM))\n",
    "        try:\n",
    "            from_candidate_target_seq[0,0,:] = w2v_model[index_to_word[candidate_token_index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        candidate_states_value = [h_true, c_true]\n",
    "\n",
    "    return candidate_joint_log_prob, candidate_target_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "file = open(\"candidate_jll_300_word2vec_bidirectional_small_imdb.csv\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove 100: processing document 0\n",
      "glove 100: processing document 1000\n",
      "glove 100: processing document 2000\n",
      "glove 100: processing document 3000\n",
      "glove 100: processing document 4000\n",
      "glove 100: processing document 5000\n",
      "glove 100: processing document 6000\n",
      "glove 100: processing document 7000\n",
      "glove 100: processing document 8000\n",
      "glove 100: processing document 9000\n",
      "glove 100: processing document 10000\n",
      "glove 100: processing document 11000\n",
      "glove 100: processing document 12000\n",
      "glove 100: processing document 13000\n",
      "glove 100: processing document 14000\n",
      "glove 100: processing document 15000\n",
      "glove 100: processing document 16000\n",
      "glove 100: processing document 17000\n",
      "glove 100: processing document 18000\n",
      "glove 100: processing document 19000\n",
      "glove 100: processing document 20000\n",
      "glove 100: processing document 21000\n",
      "glove 100: processing document 22000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 42406 is out of bounds for axis 2 with size 42406",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3158736e7806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_candidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcandidate_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_last_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcandidate_jll_per_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-ac3ddc3cfe41>\u001b[0m in \u001b[0;36mdecode_sequence_target\u001b[0;34m(candidate_states_value, candidate_target_seq)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrom_candidate_target_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcandidate_target_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcandidate_joint_log_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_target_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 42406 is out of bounds for axis 2 with size 42406"
     ]
    }
   ],
   "source": [
    "for doc in X_tr_padded:\n",
    "    y_candidate = generate_candidate_list(doc)\n",
    "    \n",
    "    candidate_jll_per_doc = []\n",
    "    input_seq = encoder_input_data[i:i+1]\n",
    "    \n",
    "    true_target_index = target_index(i, y_candidate, y_tr_padded[i])\n",
    "#     print(y_candidate)\n",
    "    # Encode\n",
    "    candidate_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    for j in range(y_candidate.shape[0]):\n",
    "        candidate_seq = y_candidate[j:j+1]\n",
    "        candidate_jll_slide, candidate_last_prob = decode_sequence_target(candidate_states_value, candidate_seq)\n",
    "        candidate_jll_per_doc.append(candidate_jll_slide)\n",
    "\n",
    "    candidate_jll_per_doc = np.asarray(candidate_jll_per_doc)\n",
    "    max_jll_index = np.argmax(candidate_jll_per_doc)\n",
    "    true_target_jll = np.around(candidate_jll_per_doc[true_target_index],5)\n",
    "    max_candidate_jll = np.around(candidate_jll_per_doc[max_jll_index],5)\n",
    "    \n",
    "    # get recall here\n",
    "    [precision, recall, f_score] = rouge_one(y_train_target[i], to_sequence(y_candidate[max_jll_index]), 1)\n",
    "    \n",
    "    file.write('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\n' %(i, true_target_index, y_train_target[i],\n",
    "                                                            max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "                                                            -(true_target_index-max_jll_index),\n",
    "                                                            true_target_jll, max_candidate_jll,\n",
    "                                                            np.absolute(true_target_jll-max_candidate_jll),\n",
    "                                                            len(intersection(y_tr_padded[i], y_candidate[max_jll_index])),\n",
    "                                                            np.exp(true_target_jll/4), np.exp(max_candidate_jll/4),\n",
    "                                                            precision, recall, f_score))\n",
    "    \n",
    "#     print('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\n' %(i, true_target_index, y['text'][i],\n",
    "#                                                             max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "#                                                             -(true_target_index-max_jll_index),\n",
    "#                                                             true_target_jll, max_candidate_jll,\n",
    "#                                                             np.absolute(true_target_jll-max_candidate_jll),\n",
    "#                                                             len(intersection(y['padded'][i], y_candidate[max_jll_index]))))\n",
    "\n",
    "#     print('%s\\t%s\\t%.1f\\n' %(y_train_target[i], to_sequence(y_candidate[max_jll_index]), precision, recall))\n",
    "    if i % 1000 == 0:\n",
    "#         print('Processing document %d...' %(i))\n",
    "        msg = 'glove 100: processing document ' + str(i)\n",
    "        u.slack_post_message(slack, msg, 'deep-learning', 'test')\n",
    "        print(msg)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "file.close()\n",
    "report_stats('Processing DONE', 'deep-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
