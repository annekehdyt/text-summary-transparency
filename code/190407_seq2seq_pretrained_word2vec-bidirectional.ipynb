{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4826293830467227931\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7401435956\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 10145428503945880758\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional\n",
    "\n",
    "https://stackoverflow.com/questions/47923370/keras-bidirectional-lstm-seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import gensim\n",
    "import keras as k\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "import util as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto(device_count={\"CPU\": 8})\n",
    "# k.backend.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Slacker Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to anneke@iitml.\n"
     ]
    }
   ],
   "source": [
    "slack = u.initiate_slacker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Google's pretrained word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('../../data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequence = u.open_pickle('../../data/imdb/X_tr_sample_original.pkl')\n",
    "X_test_sequence = u.open_pickle('../../data/imdb/X_te_sample_original.pkl')\n",
    "y_train_target = u.open_pickle('../../data/imdb/y_tr_target_original.pkl')\n",
    "y_test_target = u.open_pickle('../../data/imdb/y_te_target_original.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_target = [' '.join(['UNK', y]) for y in y_train_target]\n",
    "y_test_target = [' '.join(['UNK', y]) for y in y_test_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNK was an excellent show it'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize constant here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ENCODER_SEQ_LEN = 81\n",
    "MAX_DECODER_SEQ_LEN = 6 #include <UNK>\n",
    "EMBEDDING_DIM = 300\n",
    "LATENT_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the train sequence data\n",
    "tokenizer = k.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_sequence)\n",
    "\n",
    "# Generate text to integer sequence with post padding\n",
    "X_tr_padded = pad_sequences(tokenizer.texts_to_sequences(X_train_sequence), maxlen=MAX_ENCODER_SEQ_LEN, padding='post', truncating='post')\n",
    "y_tr_padded = pad_sequences(tokenizer.texts_to_sequences(y_train_target), maxlen=MAX_DECODER_SEQ_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   60,   241,     5,     3,   716,   258,     5,   439, 23995,\n",
       "           3,  1087,    65,    36,   129,   408,    17,    12,    79,\n",
       "           5,    24,   181,  1544, 12813,     4,   625,     2,  1720,\n",
       "        1253,   695,    30,    46,   479,   264,   200,    17,    12,\n",
       "         208,     6,    98,    10,    56,     3,   167, 10118,    36,\n",
       "         129,   408,    21,  2757,   227,   101,    32,  3166,  2188,\n",
       "           2, 23996,  2189,    17,    11,    82,    12,    61,    98,\n",
       "         108,  1440,   515,     8,   160,    22,   301,     1,   202,\n",
       "         184,    50,     5,    57,  1501,   160,    43,     8,    81],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DECODER_TOKENS = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42406"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DECODER_TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the container for input sequence decoder and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(X_train_sequence), MAX_ENCODER_SEQ_LEN, EMBEDDING_DIM),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(y_train_target), MAX_DECODER_SEQ_LEN, EMBEDDING_DIM),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(y_train_target), MAX_DECODER_SEQ_LEN, len(tokenizer.word_index)),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {v: k for k, v in tokenizer.word_index.items()}\n",
    "index_to_word[0] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_sequence, target_sequence) in enumerate(zip(X_tr_padded, y_tr_padded)):\n",
    "    # embed the input sequence\n",
    "    for t, index in enumerate(input_sequence):\n",
    "        try:\n",
    "            encoder_input_data[i, t, :] = w2v_model[index_to_word[index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "    \n",
    "    # embed the input decoder\n",
    "    for t, index in enumerate(target_sequence):\n",
    "        try:\n",
    "            decoder_input_data[i, t, :] = w2v_model[index_to_word[index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "    for t, index in enumerate(target_sequence):\n",
    "        # not include the first <UNK>\n",
    "        if t>0:\n",
    "            decoder_target_data[i, t - 1, index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = k.callbacks.ModelCheckpoint(save_best_only=True, monitor='val_loss', filepath='./300_word2vec_bidirectional_best_model/weights.{epoch:04d}-{val_loss:.3f}.h5')\n",
    "csvlogger = k.callbacks.CSVLogger(filename='word2vec_300_bidirectional_history.log', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = k.layers.Input(shape=(None, EMBEDDING_DIM))\n",
    "# encoder = k.layers.Bidirectional(LSTM(LATENT_DIM, return_state=True))\n",
    "# # encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "# # encoder_states = [state_h, state_c]\n",
    "# state_h = k.layers.Concatenate()([forward_h, backward_h])\n",
    "# state_c = k.layers.Concatenate()([forward_c, backward_c])\n",
    "# encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_inputs = k.layers.Input(shape=(None, EMBEDDING_DIM))\n",
    "# decoder_lstm = LSTM(2*LATENT_DIM, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                     initial_state=encoder_states)\n",
    "\n",
    "# decoder_dense = k.layers.Dense(NUM_DECODER_TOKENS, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model = k.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# train_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15168 samples, validate on 7584 samples\n",
      "Epoch 1/200\n",
      "15168/15168 [==============================] - 59s 4ms/step - loss: 5.6877 - val_loss: 4.2168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anneke/.local/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'concatenate_1/concat:0' shape=(?, 200) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, 200) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "15168/15168 [==============================] - 53s 4ms/step - loss: 4.0037 - val_loss: 4.0467\n",
      "Epoch 3/200\n",
      "15168/15168 [==============================] - 54s 4ms/step - loss: 3.8498 - val_loss: 3.9712\n",
      "Epoch 4/200\n",
      "15168/15168 [==============================] - 53s 4ms/step - loss: 3.7609 - val_loss: 3.9086\n",
      "Epoch 5/200\n",
      "15168/15168 [==============================] - 53s 3ms/step - loss: 3.6857 - val_loss: 3.8409\n",
      "Epoch 6/200\n",
      "15168/15168 [==============================] - 53s 4ms/step - loss: 3.6159 - val_loss: 3.7901\n",
      "Epoch 7/200\n",
      "15168/15168 [==============================] - 53s 4ms/step - loss: 3.5604 - val_loss: 3.7448\n",
      "Epoch 8/200\n",
      "15168/15168 [==============================] - 53s 3ms/step - loss: 3.5223 - val_loss: 3.7135\n",
      "Epoch 9/200\n",
      "15168/15168 [==============================] - 53s 4ms/step - loss: 3.4935 - val_loss: 3.6931\n",
      "Epoch 10/200\n",
      "15168/15168 [==============================] - 58s 4ms/step - loss: 3.4704 - val_loss: 3.6760\n",
      "Epoch 11/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.4506 - val_loss: 3.6573\n",
      "Epoch 12/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 3.4286 - val_loss: 3.6448\n",
      "Epoch 13/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 3.4127 - val_loss: 3.6273\n",
      "Epoch 14/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.3966 - val_loss: 3.6178\n",
      "Epoch 15/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.3814 - val_loss: 3.6083\n",
      "Epoch 16/200\n",
      "15168/15168 [==============================] - 69s 5ms/step - loss: 3.3680 - val_loss: 3.5949\n",
      "Epoch 17/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.3555 - val_loss: 3.5863\n",
      "Epoch 18/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 3.3426 - val_loss: 3.5750\n",
      "Epoch 19/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.3237 - val_loss: 3.5502\n",
      "Epoch 20/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 3.2890 - val_loss: 3.5228\n",
      "Epoch 21/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 3.2624 - val_loss: 3.5043\n",
      "Epoch 22/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 3.2351 - val_loss: 3.4858\n",
      "Epoch 23/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.2137 - val_loss: 3.4616\n",
      "Epoch 24/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 3.1895 - val_loss: 3.4483\n",
      "Epoch 25/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.1688 - val_loss: 3.4287\n",
      "Epoch 26/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 3.1461 - val_loss: 3.4192\n",
      "Epoch 27/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.1232 - val_loss: 3.3984\n",
      "Epoch 28/200\n",
      "15168/15168 [==============================] - 69s 5ms/step - loss: 3.1023 - val_loss: 3.3834\n",
      "Epoch 29/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 3.0829 - val_loss: 3.3665\n",
      "Epoch 30/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 3.0642 - val_loss: 3.3569\n",
      "Epoch 31/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 3.0402 - val_loss: 3.3367\n",
      "Epoch 32/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 3.0151 - val_loss: 3.3234\n",
      "Epoch 33/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.9916 - val_loss: 3.3098\n",
      "Epoch 34/200\n",
      "15168/15168 [==============================] - 69s 5ms/step - loss: 2.9691 - val_loss: 3.2982\n",
      "Epoch 35/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.9491 - val_loss: 3.2813\n",
      "Epoch 36/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.9232 - val_loss: 3.2633\n",
      "Epoch 37/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 2.9003 - val_loss: 3.2501\n",
      "Epoch 38/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.8635 - val_loss: 3.2198\n",
      "Epoch 39/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.8236 - val_loss: 3.1829\n",
      "Epoch 40/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 2.7862 - val_loss: 3.1627\n",
      "Epoch 41/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.7535 - val_loss: 3.1392\n",
      "Epoch 42/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.7224 - val_loss: 3.1193\n",
      "Epoch 43/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 2.6928 - val_loss: 3.1068\n",
      "Epoch 44/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.6566 - val_loss: 3.0830\n",
      "Epoch 45/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 2.6237 - val_loss: 3.0605\n",
      "Epoch 46/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 2.5912 - val_loss: 3.0428\n",
      "Epoch 47/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.5628 - val_loss: 3.0291\n",
      "Epoch 48/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.5306 - val_loss: 3.0137\n",
      "Epoch 49/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.5008 - val_loss: 2.9972\n",
      "Epoch 50/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 2.4712 - val_loss: 2.9778\n",
      "Epoch 51/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.4369 - val_loss: 2.9656\n",
      "Epoch 52/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 2.4118 - val_loss: 2.9498\n",
      "Epoch 53/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 2.3839 - val_loss: 2.9373\n",
      "Epoch 54/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 2.3526 - val_loss: 2.9217\n",
      "Epoch 55/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.3230 - val_loss: 2.9107\n",
      "Epoch 56/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.2954 - val_loss: 2.9022\n",
      "Epoch 57/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 2.2707 - val_loss: 2.8851\n",
      "Epoch 58/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.2402 - val_loss: 2.8751\n",
      "Epoch 59/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 2.2096 - val_loss: 2.8608\n",
      "Epoch 60/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 2.1812 - val_loss: 2.8518\n",
      "Epoch 61/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.1549 - val_loss: 2.8384\n",
      "Epoch 62/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.1268 - val_loss: 2.8288\n",
      "Epoch 63/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.0985 - val_loss: 2.8198\n",
      "Epoch 64/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.0729 - val_loss: 2.8228\n",
      "Epoch 65/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 2.0485 - val_loss: 2.8065\n",
      "Epoch 66/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 2.0256 - val_loss: 2.8038\n",
      "Epoch 67/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.9989 - val_loss: 2.7996\n",
      "Epoch 68/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.9759 - val_loss: 2.7933\n",
      "Epoch 69/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.9505 - val_loss: 2.7907\n",
      "Epoch 70/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.9266 - val_loss: 2.7824\n",
      "Epoch 71/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 1.9028 - val_loss: 2.7816\n",
      "Epoch 72/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.8789 - val_loss: 2.7731\n",
      "Epoch 73/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.8587 - val_loss: 2.7802\n",
      "Epoch 74/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.8367 - val_loss: 2.7730\n",
      "Epoch 75/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.8113 - val_loss: 2.7592\n",
      "Epoch 76/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 1.7880 - val_loss: 2.7610\n",
      "Epoch 77/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 1.7639 - val_loss: 2.7643\n",
      "Epoch 78/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.7432 - val_loss: 2.7546\n",
      "Epoch 79/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.7196 - val_loss: 2.7537\n",
      "Epoch 80/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.6960 - val_loss: 2.7517\n",
      "Epoch 81/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.6766 - val_loss: 2.7557\n",
      "Epoch 82/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.6559 - val_loss: 2.7469\n",
      "Epoch 83/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.6324 - val_loss: 2.7460\n",
      "Epoch 84/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.6121 - val_loss: 2.7498\n",
      "Epoch 85/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 1.5916 - val_loss: 2.7528\n",
      "Epoch 86/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.5700 - val_loss: 2.7469\n",
      "Epoch 87/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.5492 - val_loss: 2.7493\n",
      "Epoch 88/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.5304 - val_loss: 2.7525\n",
      "Epoch 89/200\n",
      "15168/15168 [==============================] - 69s 5ms/step - loss: 1.5110 - val_loss: 2.7544\n",
      "Epoch 90/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.4901 - val_loss: 2.7483\n",
      "Epoch 91/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.4700 - val_loss: 2.7496\n",
      "Epoch 92/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 1.4505 - val_loss: 2.7532\n",
      "Epoch 93/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.4321 - val_loss: 2.7551\n",
      "Epoch 94/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.4172 - val_loss: 2.7617\n",
      "Epoch 95/200\n",
      "15168/15168 [==============================] - 68s 5ms/step - loss: 1.3981 - val_loss: 2.7592\n",
      "Epoch 96/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 1.3788 - val_loss: 2.7566\n",
      "Epoch 97/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.3603 - val_loss: 2.7609\n",
      "Epoch 98/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.3442 - val_loss: 2.7639\n",
      "Epoch 99/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.3253 - val_loss: 2.7761\n",
      "Epoch 100/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.3096 - val_loss: 2.7761\n",
      "Epoch 101/200\n",
      "15168/15168 [==============================] - 70s 5ms/step - loss: 1.2912 - val_loss: 2.7725\n",
      "Epoch 102/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.2749 - val_loss: 2.7714\n",
      "Epoch 103/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.2560 - val_loss: 2.7737\n",
      "Epoch 104/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.2398 - val_loss: 2.7761\n",
      "Epoch 105/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.2239 - val_loss: 2.7886\n",
      "Epoch 106/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.2099 - val_loss: 2.7830\n",
      "Epoch 107/200\n",
      "15168/15168 [==============================] - 69s 5ms/step - loss: 1.1890 - val_loss: 2.7988\n",
      "Epoch 108/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.1837 - val_loss: 2.7860\n",
      "Epoch 109/200\n",
      "15168/15168 [==============================] - 73s 5ms/step - loss: 1.1603 - val_loss: 2.7950\n",
      "Epoch 110/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.1430 - val_loss: 2.8059\n",
      "Epoch 111/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.1264 - val_loss: 2.8036\n",
      "Epoch 112/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.1154 - val_loss: 2.8032\n",
      "Epoch 113/200\n",
      "15168/15168 [==============================] - 69s 5ms/step - loss: 1.0983 - val_loss: 2.8097\n",
      "Epoch 114/200\n",
      "15168/15168 [==============================] - 72s 5ms/step - loss: 1.0817 - val_loss: 2.8179\n",
      "Epoch 115/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.0694 - val_loss: 2.8193\n",
      "Epoch 116/200\n",
      "15168/15168 [==============================] - 71s 5ms/step - loss: 1.0530 - val_loss: 2.8223\n",
      "Epoch 117/200\n",
      "15104/15168 [============================>.] - ETA: 0s - loss: 1.0398"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e1e042139303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           verbose=1, callbacks=[checkpoint, csvlogger])\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_split=(1./3),\n",
    "#           verbose=1, callbacks=[checkpoint, csvlogger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f41dd7546a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./300_word2vec_bidirectional_best_model/weights.0083-2.746.h5')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 200), (None, 320800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 200),  400800      input_2[0][0]                    \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 42406)  8523606     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 9,245,206\n",
      "Trainable params: 9,245,206\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./300_word2vec_bidirectional_best_model/weights.0083-2.746.h5')\n",
    "\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs = model.layers[2].output\n",
    "\n",
    "\n",
    "encoder_outputs, forward_state_h_enc, forward_state_c_enc, backward_state_h_enc, backward_state_c_enc = model.layers[1].output\n",
    "state_h_enc = k.layers.Concatenate()([forward_state_h_enc, backward_state_h_enc])\n",
    "state_c_enc = k.layers.Concatenate()([forward_state_c_enc, backward_state_c_enc])\n",
    "\n",
    "# state_h_end = k.layers[]\n",
    "\n",
    "\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(2*LATENT_DIM,), name='input_5')\n",
    "decoder_state_input_c = Input(shape=(2*LATENT_DIM,), name='input_6')\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[5]\n",
    "\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[6]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "                    [decoder_inputs] + decoder_states_inputs,\n",
    "                    [decoder_outputs] + decoder_states\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict((i,word) for word,i in word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_list(X):\n",
    "    y_candidate = []\n",
    "    \n",
    "    for i in range(X.shape[0]-1-5):\n",
    "        y_candidate.append(X[i:i+5])\n",
    "    \n",
    "    return np.asarray(y_candidate)\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "def target_index(doc_idx, candidate_seq, y):\n",
    "    for i,j in enumerate(candidate_seq):\n",
    "        if len(intersection(j, y)) == len(y):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# doc num, doc index argmax\n",
    "\n",
    "def to_sequence(int_sequence):\n",
    "    decoded = ''\n",
    "    for i,intnum in enumerate(int_sequence):\n",
    "        if intnum == 0:\n",
    "            word = '<PAD>'\n",
    "        else:\n",
    "            word = reverse_word_index[intnum]\n",
    "        \n",
    "        if i == len(int_sequence):\n",
    "            decoded += word\n",
    "        else:\n",
    "            decoded += word + ' '\n",
    "    return decoded\n",
    "\n",
    "def rouge_one(true, candidate, start_index):\n",
    "    \n",
    "    if isinstance(true, str) and isinstance(candidate, str):\n",
    "        true = true.split()\n",
    "        candidate = candidate.split()\n",
    "    \n",
    "    overlap = [value for value in true[start_index:] if value in candidate[start_index:]] \n",
    "\n",
    "    \n",
    "    if len(true[start_index:]) != 0:\n",
    "        recall = len(overlap)/len(true[start_index:])\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if len(candidate[start_index:]):\n",
    "        precision = len(overlap)/len(candidate[start_index:])\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if (recall+precision) != 0:    \n",
    "        f1 = 2*((recall*precision)/(recall+precision))\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with candidate\n",
    "\n",
    "def decode_sequence_target(candidate_states_value, candidate_target_seq):\n",
    "#     candidate_states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    from_candidate_target_seq = np.zeros((1,1, EMBEDDING_DIM))\n",
    "    \n",
    "    candidate_token_index = candidate_target_seq[0,0]\n",
    "    try:\n",
    "        from_candidate_target_seq[0,0,:] = w2v_model[index_to_word[candidate_token_index]]\n",
    "    except KeyError as error:\n",
    "        pass\n",
    "    \n",
    "    candidate_joint_log_prob = 0\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        from_candidate_output_tokens, h_true, c_true = decoder_model.predict([from_candidate_target_seq] + candidate_states_value)\n",
    "    \n",
    "        candidate_target_prob = from_candidate_output_tokens[0,-1, candidate_target_seq[0,i]]\n",
    "        candidate_joint_log_prob += np.log(candidate_target_prob)\n",
    "        \n",
    "        # get the t+1 input\n",
    "        \n",
    "        candidate_token_index = candidate_target_seq[0,i]\n",
    "        from_candidate_target_seq = np.zeros((1,1,EMBEDDING_DIM))\n",
    "        try:\n",
    "            from_candidate_target_seq[0,0,:] = w2v_model[index_to_word[candidate_token_index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        candidate_states_value = [h_true, c_true]\n",
    "\n",
    "    return candidate_joint_log_prob, candidate_target_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "file = open(\"candidate_jll_300_word2vec_bidirectional_imdb.csv\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove 100: processing document 0\n",
      "glove 100: processing document 1000\n",
      "glove 100: processing document 2000\n",
      "glove 100: processing document 3000\n",
      "glove 100: processing document 4000\n",
      "glove 100: processing document 5000\n",
      "glove 100: processing document 6000\n",
      "glove 100: processing document 7000\n",
      "glove 100: processing document 8000\n",
      "glove 100: processing document 9000\n",
      "glove 100: processing document 10000\n",
      "glove 100: processing document 11000\n",
      "glove 100: processing document 12000\n",
      "glove 100: processing document 13000\n",
      "glove 100: processing document 14000\n",
      "glove 100: processing document 15000\n",
      "glove 100: processing document 16000\n",
      "glove 100: processing document 17000\n",
      "glove 100: processing document 18000\n",
      "glove 100: processing document 19000\n",
      "glove 100: processing document 20000\n",
      "glove 100: processing document 21000\n",
      "glove 100: processing document 22000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 42406 is out of bounds for axis 2 with size 42406",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-3158736e7806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_candidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcandidate_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_last_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcandidate_jll_per_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-ac3ddc3cfe41>\u001b[0m in \u001b[0;36mdecode_sequence_target\u001b[0;34m(candidate_states_value, candidate_target_seq)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrom_candidate_target_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcandidate_target_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcandidate_joint_log_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_target_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 42406 is out of bounds for axis 2 with size 42406"
     ]
    }
   ],
   "source": [
    "for doc in X_tr_padded:\n",
    "    y_candidate = generate_candidate_list(doc)\n",
    "    \n",
    "    candidate_jll_per_doc = []\n",
    "    input_seq = encoder_input_data[i:i+1]\n",
    "    \n",
    "    true_target_index = target_index(i, y_candidate, y_tr_padded[i])\n",
    "#     print(y_candidate)\n",
    "    # Encode\n",
    "    candidate_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    for j in range(y_candidate.shape[0]):\n",
    "        candidate_seq = y_candidate[j:j+1]\n",
    "        candidate_jll_slide, candidate_last_prob = decode_sequence_target(candidate_states_value, candidate_seq)\n",
    "        candidate_jll_per_doc.append(candidate_jll_slide)\n",
    "\n",
    "    candidate_jll_per_doc = np.asarray(candidate_jll_per_doc)\n",
    "    max_jll_index = np.argmax(candidate_jll_per_doc)\n",
    "    true_target_jll = np.around(candidate_jll_per_doc[true_target_index],5)\n",
    "    max_candidate_jll = np.around(candidate_jll_per_doc[max_jll_index],5)\n",
    "    \n",
    "    # get recall here\n",
    "    [precision, recall, f_score] = rouge_one(y_train_target[i], to_sequence(y_candidate[max_jll_index]), 1)\n",
    "    \n",
    "    file.write('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\n' %(i, true_target_index, y_train_target[i],\n",
    "                                                            max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "                                                            -(true_target_index-max_jll_index),\n",
    "                                                            true_target_jll, max_candidate_jll,\n",
    "                                                            np.absolute(true_target_jll-max_candidate_jll),\n",
    "                                                            len(intersection(y_tr_padded[i], y_candidate[max_jll_index])),\n",
    "                                                            np.exp(true_target_jll/4), np.exp(max_candidate_jll/4),\n",
    "                                                            precision, recall, f_score))\n",
    "    \n",
    "#     print('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\n' %(i, true_target_index, y['text'][i],\n",
    "#                                                             max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "#                                                             -(true_target_index-max_jll_index),\n",
    "#                                                             true_target_jll, max_candidate_jll,\n",
    "#                                                             np.absolute(true_target_jll-max_candidate_jll),\n",
    "#                                                             len(intersection(y['padded'][i], y_candidate[max_jll_index]))))\n",
    "\n",
    "#     print('%s\\t%s\\t%.1f\\n' %(y_train_target[i], to_sequence(y_candidate[max_jll_index]), precision, recall))\n",
    "    if i % 1000 == 0:\n",
    "#         print('Processing document %d...' %(i))\n",
    "        msg = 'glove 100: processing document ' + str(i)\n",
    "        u.slack_post_message(slack, msg, 'deep-learning', 'test')\n",
    "        print(msg)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "file.close()\n",
    "report_stats('Processing DONE', 'deep-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
