{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4080094264009605957\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import gensim\n",
    "import keras as k\n",
    "import chakin\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "import util as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Slacker Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to anneke@iitml.\n"
     ]
    }
   ],
   "source": [
    "slack = u.initiate_slacker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained word Fast Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name  Dimension                     Corpus VocabularySize  \\\n",
      "2          fastText(en)        300                  Wikipedia           2.5M   \n",
      "11         GloVe.6B.50d         50  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "12        GloVe.6B.100d        100  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "13        GloVe.6B.200d        200  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "14        GloVe.6B.300d        300  Wikipedia+Gigaword 5 (6B)           400K   \n",
      "15       GloVe.42B.300d        300          Common Crawl(42B)           1.9M   \n",
      "16      GloVe.840B.300d        300         Common Crawl(840B)           2.2M   \n",
      "17    GloVe.Twitter.25d         25               Twitter(27B)           1.2M   \n",
      "18    GloVe.Twitter.50d         50               Twitter(27B)           1.2M   \n",
      "19   GloVe.Twitter.100d        100               Twitter(27B)           1.2M   \n",
      "20   GloVe.Twitter.200d        200               Twitter(27B)           1.2M   \n",
      "21  word2vec.GoogleNews        300          Google News(100B)           3.0M   \n",
      "\n",
      "      Method Language    Author  \n",
      "2   fastText  English  Facebook  \n",
      "11     GloVe  English  Stanford  \n",
      "12     GloVe  English  Stanford  \n",
      "13     GloVe  English  Stanford  \n",
      "14     GloVe  English  Stanford  \n",
      "15     GloVe  English  Stanford  \n",
      "16     GloVe  English  Stanford  \n",
      "17     GloVe  English  Stanford  \n",
      "18     GloVe  English  Stanford  \n",
      "19     GloVe  English  Stanford  \n",
      "20     GloVe  English  Stanford  \n",
      "21  word2vec  English    Google  \n"
     ]
    }
   ],
   "source": [
    "chakin.search(lang='English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chakin.download(number=2, save_dir='../../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(r'../../data/cc.en.300.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequence = u.open_pickle('../../data/imdb/X_tr_sample_original.pkl')\n",
    "# X_test_sequence = u.open_pickle('../../data/imdb/X_te_sample_original.pkl')\n",
    "y_train_target = u.open_pickle('../../data/imdb/y_tr_target_original.pkl')\n",
    "# y_test_target = u.open_pickle('../../data/imdb/y_te_target_original.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_target = [' '.join(['UNK', y]) for y in y_train_target]\n",
    "# y_test_target = [' '.join(['UNK', y]) for y in y_test_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize constant here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ENCODER_SEQ_LEN = 81\n",
    "MAX_DECODER_SEQ_LEN = 6 #include <UNK>\n",
    "EMBEDDING_DIM = w2v_model.vector_size\n",
    "LATENT_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the train sequence data\n",
    "tokenizer = k.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_sequence)\n",
    "\n",
    "# Generate text to integer sequence with post padding\n",
    "X_tr_padded = pad_sequences(tokenizer.texts_to_sequences(X_train_sequence), maxlen=MAX_ENCODER_SEQ_LEN, padding='post', truncating='post')\n",
    "y_tr_padded = pad_sequences(tokenizer.texts_to_sequences(y_train_target), maxlen=MAX_DECODER_SEQ_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DECODER_TOKENS = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42406"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_DECODER_TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the container for input sequence decoder and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(X_train_sequence), MAX_ENCODER_SEQ_LEN, EMBEDDING_DIM),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(y_train_target), MAX_DECODER_SEQ_LEN, EMBEDDING_DIM),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(y_train_target), MAX_DECODER_SEQ_LEN, len(tokenizer.word_index)),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {v: k for k, v in tokenizer.word_index.items()}\n",
    "index_to_word[0] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_sequence, target_sequence) in enumerate(zip(X_tr_padded, y_tr_padded)):\n",
    "    # embed the input sequence\n",
    "    for t, index in enumerate(input_sequence):\n",
    "        try:\n",
    "            encoder_input_data[i, t, :] = w2v_model[index_to_word[index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "    \n",
    "    # embed the input decoder\n",
    "    for t, index in enumerate(target_sequence):\n",
    "        try:\n",
    "            decoder_input_data[i, t, :] = w2v_model[index_to_word[index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "    for t, index in enumerate(target_sequence):\n",
    "        # not include the first <UNK>\n",
    "        if t>0:\n",
    "            decoder_target_data[i, t - 1, index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = k.callbacks.ModelCheckpoint(save_best_only=True, monitor='val_loss', filepath='./300_fasttext_best_model/weights.{epoch:04d}-{val_loss:.3f}.h5')\n",
    "# csvlogger = k.callbacks.CSVLogger(filename='fasttext_300_history.log', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = k.layers.Input(shape=(None, EMBEDDING_DIM))\n",
    "# encoder = LSTM(LATENT_DIM, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_inputs = k.layers.Input(shape=(None, EMBEDDING_DIM))\n",
    "# decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                     initial_state=encoder_states)\n",
    "\n",
    "# decoder_dense = k.layers.Dense(NUM_DECODER_TOKENS, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model = k.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# train_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15168 samples, validate on 7584 samples\n",
      "Epoch 1/200\n",
      "15168/15168 [==============================] - 48s 3ms/step - loss: 6.5550 - val_loss: 4.3574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anneke/.local/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 4.1436 - val_loss: 4.1754\n",
      "Epoch 3/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 4.0138 - val_loss: 4.1091\n",
      "Epoch 4/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.9402 - val_loss: 4.0683\n",
      "Epoch 5/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.8889 - val_loss: 4.0402\n",
      "Epoch 6/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.8496 - val_loss: 4.0138\n",
      "Epoch 7/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.8163 - val_loss: 3.9900\n",
      "Epoch 8/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.7802 - val_loss: 3.9624\n",
      "Epoch 9/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.7340 - val_loss: 3.9115\n",
      "Epoch 10/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.6865 - val_loss: 3.8657\n",
      "Epoch 11/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.6341 - val_loss: 3.8162\n",
      "Epoch 12/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.5873 - val_loss: 3.7749\n",
      "Epoch 13/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.5486 - val_loss: 3.7447\n",
      "Epoch 14/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.5184 - val_loss: 3.7172\n",
      "Epoch 15/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.4923 - val_loss: 3.6959\n",
      "Epoch 16/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.4695 - val_loss: 3.6766\n",
      "Epoch 17/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.4504 - val_loss: 3.6623\n",
      "Epoch 18/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.4300 - val_loss: 3.6451\n",
      "Epoch 19/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.4111 - val_loss: 3.6290\n",
      "Epoch 20/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.3941 - val_loss: 3.6147\n",
      "Epoch 21/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.3760 - val_loss: 3.5987\n",
      "Epoch 22/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.3569 - val_loss: 3.5799\n",
      "Epoch 23/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.3381 - val_loss: 3.5663\n",
      "Epoch 24/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.3188 - val_loss: 3.5500\n",
      "Epoch 25/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.2997 - val_loss: 3.5333\n",
      "Epoch 26/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.2821 - val_loss: 3.5223\n",
      "Epoch 27/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.3452 - val_loss: 3.5063\n",
      "Epoch 28/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.2476 - val_loss: 3.4874\n",
      "Epoch 29/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.2276 - val_loss: 3.4750\n",
      "Epoch 30/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.2098 - val_loss: 3.4620\n",
      "Epoch 31/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.1931 - val_loss: 3.4435\n",
      "Epoch 32/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.1737 - val_loss: 3.4328\n",
      "Epoch 33/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.1569 - val_loss: 3.4166\n",
      "Epoch 34/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.1392 - val_loss: 3.4022\n",
      "Epoch 35/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.1541 - val_loss: 3.3951\n",
      "Epoch 36/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.1129 - val_loss: 3.3805\n",
      "Epoch 37/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.0893 - val_loss: 3.3631\n",
      "Epoch 38/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.0678 - val_loss: 3.3437\n",
      "Epoch 39/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.0485 - val_loss: 3.3334\n",
      "Epoch 40/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.0292 - val_loss: 3.3158\n",
      "Epoch 41/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 3.0114 - val_loss: 3.3013\n",
      "Epoch 42/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.9927 - val_loss: 3.2900\n",
      "Epoch 43/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.9741 - val_loss: 3.2769\n",
      "Epoch 44/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.9581 - val_loss: 3.2683\n",
      "Epoch 45/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.9396 - val_loss: 3.2590\n",
      "Epoch 46/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.9224 - val_loss: 3.2445\n",
      "Epoch 47/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.9058 - val_loss: 3.2293\n",
      "Epoch 48/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.8877 - val_loss: 3.2210\n",
      "Epoch 49/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.8715 - val_loss: 3.2110\n",
      "Epoch 50/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.8548 - val_loss: 3.2006\n",
      "Epoch 51/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.8384 - val_loss: 3.1933\n",
      "Epoch 52/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.8230 - val_loss: 3.1831\n",
      "Epoch 53/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.8088 - val_loss: 3.1734\n",
      "Epoch 54/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.7932 - val_loss: 3.1705\n",
      "Epoch 55/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.7794 - val_loss: 3.1616\n",
      "Epoch 56/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.7663 - val_loss: 3.1547\n",
      "Epoch 57/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.7522 - val_loss: 3.1492\n",
      "Epoch 58/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.7394 - val_loss: 3.1457\n",
      "Epoch 59/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.7273 - val_loss: 3.1345\n",
      "Epoch 60/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.7128 - val_loss: 3.1312\n",
      "Epoch 61/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6988 - val_loss: 3.1203\n",
      "Epoch 62/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6862 - val_loss: 3.1168\n",
      "Epoch 63/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6748 - val_loss: 3.1122\n",
      "Epoch 64/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6616 - val_loss: 3.1059\n",
      "Epoch 65/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6481 - val_loss: 3.1047\n",
      "Epoch 66/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6371 - val_loss: 3.0978\n",
      "Epoch 67/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6260 - val_loss: 3.0923\n",
      "Epoch 68/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6133 - val_loss: 3.0910\n",
      "Epoch 69/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.6023 - val_loss: 3.0847\n",
      "Epoch 70/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.5911 - val_loss: 3.0789\n",
      "Epoch 71/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.5759 - val_loss: 3.0725\n",
      "Epoch 72/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.5654 - val_loss: 3.0725\n",
      "Epoch 73/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.5527 - val_loss: 3.0696\n",
      "Epoch 74/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.5388 - val_loss: 3.0581\n",
      "Epoch 75/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.5299 - val_loss: 3.0567\n",
      "Epoch 76/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.5157 - val_loss: 3.0524\n",
      "Epoch 77/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.5025 - val_loss: 3.0429\n",
      "Epoch 78/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.4889 - val_loss: 3.0364\n",
      "Epoch 79/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.4780 - val_loss: 3.0311\n",
      "Epoch 80/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.4636 - val_loss: 3.0281\n",
      "Epoch 81/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.4518 - val_loss: 3.0219\n",
      "Epoch 82/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.4401 - val_loss: 3.0251\n",
      "Epoch 83/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.4290 - val_loss: 3.0131\n",
      "Epoch 84/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.4182 - val_loss: 3.0094\n",
      "Epoch 85/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.4042 - val_loss: 3.0089\n",
      "Epoch 86/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3944 - val_loss: 3.0051\n",
      "Epoch 87/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3827 - val_loss: 2.9968\n",
      "Epoch 88/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3690 - val_loss: 2.9950\n",
      "Epoch 89/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3612 - val_loss: 2.9913\n",
      "Epoch 90/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3470 - val_loss: 2.9884\n",
      "Epoch 91/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3375 - val_loss: 2.9873\n",
      "Epoch 92/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3253 - val_loss: 2.9860\n",
      "Epoch 93/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3154 - val_loss: 2.9776\n",
      "Epoch 94/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.3025 - val_loss: 2.9746\n",
      "Epoch 95/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2934 - val_loss: 2.9739\n",
      "Epoch 96/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2814 - val_loss: 2.9665\n",
      "Epoch 97/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2693 - val_loss: 2.9725\n",
      "Epoch 98/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2613 - val_loss: 2.9754\n",
      "Epoch 99/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2494 - val_loss: 2.9592\n",
      "Epoch 100/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2368 - val_loss: 2.9538\n",
      "Epoch 101/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2255 - val_loss: 2.9583\n",
      "Epoch 102/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2158 - val_loss: 2.9574\n",
      "Epoch 103/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.2054 - val_loss: 2.9432\n",
      "Epoch 104/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1938 - val_loss: 2.9472\n",
      "Epoch 105/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1854 - val_loss: 2.9415\n",
      "Epoch 106/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1732 - val_loss: 2.9384\n",
      "Epoch 107/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1626 - val_loss: 2.9432\n",
      "Epoch 108/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1520 - val_loss: 2.9332\n",
      "Epoch 109/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1414 - val_loss: 2.9289\n",
      "Epoch 110/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1307 - val_loss: 2.9264\n",
      "Epoch 111/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1229 - val_loss: 2.9285\n",
      "Epoch 112/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1170 - val_loss: 2.9237\n",
      "Epoch 113/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.1033 - val_loss: 2.9374\n",
      "Epoch 114/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0954 - val_loss: 2.9228\n",
      "Epoch 115/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0858 - val_loss: 2.9182\n",
      "Epoch 116/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0748 - val_loss: 2.9179\n",
      "Epoch 117/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0658 - val_loss: 2.9181\n",
      "Epoch 118/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0568 - val_loss: 2.9161\n",
      "Epoch 119/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0466 - val_loss: 2.9215\n",
      "Epoch 120/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0369 - val_loss: 2.9189\n",
      "Epoch 121/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0303 - val_loss: 2.9117\n",
      "Epoch 122/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0210 - val_loss: 2.9158\n",
      "Epoch 123/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0117 - val_loss: 2.9181\n",
      "Epoch 124/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 2.0010 - val_loss: 2.9138\n",
      "Epoch 125/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9907 - val_loss: 2.9122\n",
      "Epoch 126/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9840 - val_loss: 2.9082\n",
      "Epoch 127/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9758 - val_loss: 2.9079\n",
      "Epoch 128/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9661 - val_loss: 2.9351\n",
      "Epoch 129/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9593 - val_loss: 2.9098\n",
      "Epoch 130/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9502 - val_loss: 2.9064\n",
      "Epoch 131/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9376 - val_loss: 2.9036\n",
      "Epoch 132/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9288 - val_loss: 2.9091\n",
      "Epoch 133/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9196 - val_loss: 2.9097\n",
      "Epoch 134/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9129 - val_loss: 2.9140\n",
      "Epoch 135/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.9030 - val_loss: 2.9023\n",
      "Epoch 136/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8955 - val_loss: 2.9027\n",
      "Epoch 137/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8843 - val_loss: 2.9080\n",
      "Epoch 138/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8776 - val_loss: 2.9009\n",
      "Epoch 139/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8680 - val_loss: 2.9027\n",
      "Epoch 140/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8629 - val_loss: 2.9023\n",
      "Epoch 141/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8490 - val_loss: 2.8950\n",
      "Epoch 142/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8411 - val_loss: 2.8974\n",
      "Epoch 143/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8346 - val_loss: 2.9202\n",
      "Epoch 144/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8291 - val_loss: 2.8996\n",
      "Epoch 145/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8178 - val_loss: 2.9003\n",
      "Epoch 146/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8082 - val_loss: 2.9140\n",
      "Epoch 147/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.8028 - val_loss: 2.8950\n",
      "Epoch 148/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7917 - val_loss: 2.9061\n",
      "Epoch 149/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7845 - val_loss: 2.9060\n",
      "Epoch 150/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7787 - val_loss: 2.8987\n",
      "Epoch 151/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7677 - val_loss: 2.9062\n",
      "Epoch 152/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7565 - val_loss: 2.9013\n",
      "Epoch 153/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7504 - val_loss: 2.9020\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7407 - val_loss: 2.8996\n",
      "Epoch 155/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7318 - val_loss: 2.8959\n",
      "Epoch 156/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7267 - val_loss: 2.8988\n",
      "Epoch 157/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7162 - val_loss: 2.8951\n",
      "Epoch 158/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7124 - val_loss: 2.8965\n",
      "Epoch 159/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.7036 - val_loss: 2.8997\n",
      "Epoch 160/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6903 - val_loss: 2.9169\n",
      "Epoch 161/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6852 - val_loss: 2.8981\n",
      "Epoch 162/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6742 - val_loss: 2.9005\n",
      "Epoch 163/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6688 - val_loss: 2.8996\n",
      "Epoch 164/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6600 - val_loss: 2.9047\n",
      "Epoch 165/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6536 - val_loss: 2.8984\n",
      "Epoch 166/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6431 - val_loss: 2.9013\n",
      "Epoch 167/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6345 - val_loss: 2.9075\n",
      "Epoch 168/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6319 - val_loss: 2.8932\n",
      "Epoch 169/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6207 - val_loss: 2.8961\n",
      "Epoch 170/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.6100 - val_loss: 2.8961\n",
      "Epoch 171/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5998 - val_loss: 2.8944\n",
      "Epoch 172/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5948 - val_loss: 2.9061\n",
      "Epoch 173/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5927 - val_loss: 2.8964\n",
      "Epoch 174/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5800 - val_loss: 2.9125\n",
      "Epoch 175/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5746 - val_loss: 2.9007\n",
      "Epoch 176/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5617 - val_loss: 2.9096\n",
      "Epoch 177/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5589 - val_loss: 2.9086\n",
      "Epoch 178/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5483 - val_loss: 2.9076\n",
      "Epoch 179/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5505 - val_loss: 2.9048\n",
      "Epoch 180/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5352 - val_loss: 2.9072\n",
      "Epoch 181/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5287 - val_loss: 2.9063\n",
      "Epoch 182/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5248 - val_loss: 2.9075\n",
      "Epoch 183/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5137 - val_loss: 2.9045\n",
      "Epoch 184/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.5072 - val_loss: 2.9024\n",
      "Epoch 185/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4982 - val_loss: 2.9137\n",
      "Epoch 186/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4950 - val_loss: 2.9121\n",
      "Epoch 187/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4850 - val_loss: 2.9210\n",
      "Epoch 188/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4848 - val_loss: 2.9168\n",
      "Epoch 189/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4705 - val_loss: 2.9176\n",
      "Epoch 190/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4639 - val_loss: 2.9200\n",
      "Epoch 191/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4582 - val_loss: 2.9225\n",
      "Epoch 192/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4526 - val_loss: 2.9292\n",
      "Epoch 193/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4458 - val_loss: 2.9336\n",
      "Epoch 194/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4418 - val_loss: 2.9377\n",
      "Epoch 195/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4393 - val_loss: 2.9282\n",
      "Epoch 196/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4279 - val_loss: 2.9217\n",
      "Epoch 197/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4203 - val_loss: 2.9302\n",
      "Epoch 198/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4128 - val_loss: 2.9314\n",
      "Epoch 199/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4071 - val_loss: 2.9317\n",
      "Epoch 200/200\n",
      "15168/15168 [==============================] - 42s 3ms/step - loss: 1.4031 - val_loss: 2.9458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f089c1e0ef0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_split=(1./3),\n",
    "#           verbose=1, callbacks=[checkpoint, csvlogger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./300_fasttext_best_model/weights.0168-2.893.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 100), (None, 160400      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 100),  160400      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 42406)  4283006     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,603,806\n",
      "Trainable params: 4,603,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./300_fasttext_best_model/weights.0168-2.893.h5')\n",
    "\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,), name='input_5')\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,), name='input_6')\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[3]\n",
    "\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "                    [decoder_inputs] + decoder_states_inputs,\n",
    "                    [decoder_outputs] + decoder_states\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict((i,word) for word,i in word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_list(X):\n",
    "    y_candidate = []\n",
    "    \n",
    "    for i in range(X.shape[0]-1-5):\n",
    "        y_candidate.append(X[i:i+5])\n",
    "    \n",
    "    return np.asarray(y_candidate)\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "def target_index(doc_idx, candidate_seq, y):\n",
    "    for i,j in enumerate(candidate_seq):\n",
    "        if len(intersection(j, y)) == len(y):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# doc num, doc index argmax\n",
    "\n",
    "def to_sequence(int_sequence):\n",
    "    decoded = ''\n",
    "    for i,intnum in enumerate(int_sequence):\n",
    "        if intnum == 0:\n",
    "            word = '<PAD>'\n",
    "        else:\n",
    "            word = reverse_word_index[intnum]\n",
    "        \n",
    "        if i == len(int_sequence):\n",
    "            decoded += word\n",
    "        else:\n",
    "            decoded += word + ' '\n",
    "    return decoded\n",
    "\n",
    "def rouge_one(true, candidate, start_index):\n",
    "    \n",
    "    if isinstance(true, str) and isinstance(candidate, str):\n",
    "        true = true.split()\n",
    "        candidate = candidate.split()\n",
    "    \n",
    "    overlap = [value for value in true[start_index:] if value in candidate[start_index:]] \n",
    "\n",
    "    \n",
    "    if len(true[start_index:]) != 0:\n",
    "        recall = len(overlap)/len(true[start_index:])\n",
    "    else:\n",
    "        recall = 0\n",
    "    \n",
    "    if len(candidate[start_index:]):\n",
    "        precision = len(overlap)/len(candidate[start_index:])\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if (recall+precision) != 0:    \n",
    "        f1 = 2*((recall*precision)/(recall+precision))\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with candidate\n",
    "\n",
    "def decode_sequence_target(candidate_states_value, candidate_target_seq):\n",
    "#     candidate_states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    from_candidate_target_seq = np.zeros((1,1, EMBEDDING_DIM))\n",
    "    \n",
    "    candidate_token_index = candidate_target_seq[0,0]\n",
    "    try:\n",
    "        from_candidate_target_seq[0,0,:] = w2v_model[index_to_word[candidate_token_index]]\n",
    "    except KeyError as error:\n",
    "        pass\n",
    "    \n",
    "    candidate_joint_log_prob = 0\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        from_candidate_output_tokens, h_true, c_true = decoder_model.predict([from_candidate_target_seq] + candidate_states_value)\n",
    "    \n",
    "        candidate_target_prob = from_candidate_output_tokens[0,-1, candidate_target_seq[0,i]]\n",
    "        candidate_joint_log_prob += np.log(candidate_target_prob)\n",
    "        \n",
    "        # get the t+1 input\n",
    "        \n",
    "        candidate_token_index = candidate_target_seq[0,i]\n",
    "        from_candidate_target_seq = np.zeros((1,1,EMBEDDING_DIM))\n",
    "        try:\n",
    "            from_candidate_target_seq[0,0,:] = w2v_model[index_to_word[candidate_token_index]]\n",
    "        except KeyError as error:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        candidate_states_value = [h_true, c_true]\n",
    "\n",
    "    return candidate_joint_log_prob, candidate_target_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "file = open(\"candidate_jll_300_fasttext_imdb.csv\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove 100: processing document 0\n",
      "glove 100: processing document 1000\n",
      "glove 100: processing document 2000\n",
      "glove 100: processing document 3000\n",
      "glove 100: processing document 4000\n",
      "glove 100: processing document 5000\n",
      "glove 100: processing document 6000\n",
      "glove 100: processing document 7000\n",
      "glove 100: processing document 8000\n",
      "glove 100: processing document 9000\n",
      "glove 100: processing document 10000\n",
      "glove 100: processing document 11000\n",
      "glove 100: processing document 12000\n",
      "glove 100: processing document 13000\n",
      "glove 100: processing document 14000\n",
      "glove 100: processing document 15000\n",
      "glove 100: processing document 16000\n",
      "glove 100: processing document 17000\n",
      "glove 100: processing document 18000\n",
      "glove 100: processing document 19000\n",
      "glove 100: processing document 20000\n",
      "glove 100: processing document 21000\n",
      "glove 100: processing document 22000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 42406 is out of bounds for axis 2 with size 42406",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3158736e7806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_candidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcandidate_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_last_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcandidate_jll_per_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_jll_slide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-ac3ddc3cfe41>\u001b[0m in \u001b[0;36mdecode_sequence_target\u001b[0;34m(candidate_states_value, candidate_target_seq)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrom_candidate_target_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcandidate_states_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcandidate_target_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_candidate_output_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcandidate_joint_log_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_target_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 42406 is out of bounds for axis 2 with size 42406"
     ]
    }
   ],
   "source": [
    "for doc in X_tr_padded:\n",
    "    y_candidate = generate_candidate_list(doc)\n",
    "    \n",
    "    candidate_jll_per_doc = []\n",
    "    input_seq = encoder_input_data[i:i+1]\n",
    "    \n",
    "    true_target_index = target_index(i, y_candidate, y_tr_padded[i])\n",
    "#     print(y_candidate)\n",
    "    # Encode\n",
    "    candidate_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    for j in range(y_candidate.shape[0]):\n",
    "        candidate_seq = y_candidate[j:j+1]\n",
    "        candidate_jll_slide, candidate_last_prob = decode_sequence_target(candidate_states_value, candidate_seq)\n",
    "        candidate_jll_per_doc.append(candidate_jll_slide)\n",
    "\n",
    "    candidate_jll_per_doc = np.asarray(candidate_jll_per_doc)\n",
    "    max_jll_index = np.argmax(candidate_jll_per_doc)\n",
    "    true_target_jll = np.around(candidate_jll_per_doc[true_target_index],5)\n",
    "    max_candidate_jll = np.around(candidate_jll_per_doc[max_jll_index],5)\n",
    "    \n",
    "    # get recall here\n",
    "    [precision, recall, f_score] = rouge_one(y_train_target[i], to_sequence(y_candidate[max_jll_index]), 1)\n",
    "    \n",
    "    file.write('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\t%.5f\\n' %(i, true_target_index, y_train_target[i],\n",
    "                                                            max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "                                                            -(true_target_index-max_jll_index),\n",
    "                                                            true_target_jll, max_candidate_jll,\n",
    "                                                            np.absolute(true_target_jll-max_candidate_jll),\n",
    "                                                            len(intersection(y_tr_padded[i], y_candidate[max_jll_index])),\n",
    "                                                            np.exp(true_target_jll/4), np.exp(max_candidate_jll/4),\n",
    "                                                            precision, recall, f_score))\n",
    "    \n",
    "#     print('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\n' %(i, true_target_index, y['text'][i],\n",
    "#                                                             max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "#                                                             -(true_target_index-max_jll_index),\n",
    "#                                                             true_target_jll, max_candidate_jll,\n",
    "#                                                             np.absolute(true_target_jll-max_candidate_jll),\n",
    "#                                                             len(intersection(y['padded'][i], y_candidate[max_jll_index]))))\n",
    "\n",
    "#     print('%s\\t%s\\t%.1f\\n' %(y_train_target[i], to_sequence(y_candidate[max_jll_index]), precision, recall))\n",
    "    if i % 1000 == 0:\n",
    "#         print('Processing document %d...' %(i))\n",
    "        msg = 'glove 100: processing document ' + str(i)\n",
    "        u.slack_post_message(slack, msg, 'deep-learning', 'test')\n",
    "        print(msg)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "file.close()\n",
    "report_stats('Processing DONE', 'deep-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
