{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load keras seq2seq model\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq_restore.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3623874767986761113\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the necessary initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = open_pickle('../../data/imdb_sequence/3000_one_hot/X_tr_seq_set.pkl')\n",
    "y = open_pickle('../../data/imdb_sequence/3000_one_hot/y_tr_seq_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer\n",
    "MAX_NUM_WORDS = 1000\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 100\n",
    "NUM_ENCODER_TOKENS = np.max(X['padded']+1)\n",
    "NUM_DECODER_TOKENS = np.max(X['padded']+1)\n",
    "max_encoder_seq_length = X['padded'].shape[1]\n",
    "max_decoder_seq_length = X['padded'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (1000, max_encoder_seq_length, NUM_ENCODER_TOKENS),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (1000, max_decoder_seq_length, NUM_DECODER_TOKENS),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (1000, max_decoder_seq_length, NUM_DECODER_TOKENS),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(X['padded'][:1000], y['padded'][:1000])):\n",
    "    for t, word in enumerate(input_text):\n",
    "        encoder_input_data[i, t, word] = 1.\n",
    "        \n",
    "    for t, word in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, word] = 1.\n",
    "        \n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, word] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('3000_one_hot_s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name='input_3')\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name='input_4')\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = model.layers[3]\n",
    "\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "decoder_inputs, initial_state=decoder_states_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "                    [decoder_inputs] + decoder_states_inputs,\n",
    "                    [decoder_outputs] + decoder_states\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate_list(X):\n",
    "    y_candidate = []\n",
    "    \n",
    "    for i in range(X.shape[0]-1-5):\n",
    "        y_candidate.append(X[i:i+5])\n",
    "    \n",
    "    return np.asarray(y_candidate)\n",
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "def target_index(doc_idx, candidate_seq, y):\n",
    "    for i,j in enumerate(candidate_seq):\n",
    "        if len(intersection(j, y)) == len(y):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "# doc num, doc index argmax\n",
    "\n",
    "def to_sequence(int_sequence):\n",
    "    decoded = ''\n",
    "    for i in int_sequence:\n",
    "        if i == 0:\n",
    "            word = ' '\n",
    "        else:\n",
    "            word = reverse_word_index[i]\n",
    "        decoded += word + ' '\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with candidate\n",
    "\n",
    "def decode_sequence_target(candidate_states_value, candidate_target_seq):\n",
    "#     candidate_states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    from_candidate_target_seq = np.zeros((1,1, NUM_DECODER_TOKENS))\n",
    "    candidate_token_index = candidate_target_seq[0,0]\n",
    "    from_candidate_target_seq[0,0,candidate_token_index] = 1.\n",
    "    candidate_joint_log_prob = 0\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        from_candidate_output_tokens, h_true, c_true = decoder_model.predict([from_candidate_target_seq] + candidate_states_value)\n",
    "    \n",
    "        candidate_target_prob = from_candidate_output_tokens[0,-1, candidate_target_seq[0,i]]\n",
    "        candidate_token_index = candidate_target_seq[0,i]\n",
    "        candidate_joint_log_prob += np.log(candidate_target_prob)\n",
    "        \n",
    "        # get the t+1 input\n",
    "        from_candidate_target_seq = np.zeros((1,1,NUM_DECODER_TOKENS))\n",
    "        from_candidate_target_seq[0,0,candidate_token_index] = 1.\n",
    "        \n",
    "        candidate_states_value = [h_true, c_true]\n",
    "\n",
    "    return candidate_joint_log_prob, candidate_target_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict((i,word) for word,i in word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t40\tmake this great a few\t40\tmake this great a few \t0\t-16.40715\t-16.40715\t0.00000\t5\t0.01654\t0.01654\n",
      "\n",
      "Processing document 0...\n",
      "1\t40\tfilm of excellent quality that\t40\tfilm of excellent quality that \t0\t-11.66289\t-11.66289\t0.00000\t5\t0.05416\t0.05416\n",
      "\n",
      "2\t44\tat its best although the\t44\tat its best although the \t0\t-4.78549\t-4.78549\t0.00000\t5\t0.30229\t0.30229\n",
      "\n",
      "3\t49\twhat the best of this\t49\twhat the best of this \t0\t-7.69823\t-7.69823\t0.00000\t5\t0.14594\t0.14594\n",
      "\n",
      "4\t0\tcomplete crap poor\t0\t          \t0\t-16.82497\t-16.82497\t0.00000\t2\t0.01490\t0.01490\n",
      "\n",
      "5\t53\tfor this boring adventure in\t53\tfor this boring adventure in \t0\t-17.91513\t-17.91513\t0.00000\t5\t0.01135\t0.01135\n",
      "\n",
      "6\t39\tis utterly laughable and has\t39\tis utterly laughable and has \t0\t-11.30772\t-11.30772\t0.00000\t5\t0.05919\t0.05919\n",
      "\n",
      "7\t60\tare mainly poor cgi and\t60\tare mainly poor cgi and \t0\t-6.95309\t-6.95309\t0.00000\t5\t0.17582\t0.17582\n",
      "\n",
      "8\t0\tearned the best actor oscar\t46\the the best actor oscar \t46\t-30.84245\t-19.72124\t11.12121\t4\t0.00045\t0.00722\n",
      "\n",
      "9\t38\tit the best they can\t38\tit the best they can \t0\t-5.44498\t-5.44498\t0.00000\t5\t0.25634\t0.25634\n",
      "\n",
      "10\t40\tout loud funny watching her\t40\tout loud funny watching her \t0\t-3.48957\t-3.48957\t0.00000\t5\t0.41795\t0.41795\n",
      "\n",
      "11\t41\tof the best picture ever\t0\t          \t-41\t-7.21116\t-3.29654\t3.91462\t0\t0.16484\t0.43861\n",
      "\n",
      "12\t40\tlighting was terrible and i\t40\tlighting was terrible and i \t0\t-4.02712\t-4.02712\t0.00000\t5\t0.36539\t0.36539\n",
      "\n",
      "13\t42\tgood product unfortunately he will\t42\tgood product unfortunately he will \t0\t-2.67318\t-2.67318\t0.00000\t5\t0.51258\t0.51258\n",
      "\n",
      "14\t39\tshe was wasted here one\t39\tshe was wasted here one \t0\t-8.48368\t-8.48368\t0.00000\t5\t0.11992\t0.11992\n",
      "\n",
      "15\t0\tscientific arguments avoid this film\t0\t          \t0\t-9.06737\t-9.06737\t0.00000\t2\t0.10364\t0.10364\n",
      "\n",
      "16\t41\ttrying to mess with the\t41\ttrying to mess with the \t0\t-5.48058\t-5.48058\t0.00000\t5\t0.25407\t0.25407\n",
      "\n",
      "17\t0\tchoppy and annoying he seems\t40\tis and annoying he seems \t40\t-23.72991\t-20.15837\t3.57154\t4\t0.00265\t0.00648\n",
      "\n",
      "18\t40\ttries her best it has\t0\t          \t-40\t-7.39577\t-5.81274\t1.58303\t0\t0.15740\t0.23382\n",
      "\n",
      "19\t39\teven that awful american werewolf\t47\tit is fun to watch \t8\t-11.33522\t-3.62250\t7.71272\t0\t0.05879\t0.40429\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d81b466a11db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "for doc in X['padded'][:20]:\n",
    "    y_candidate = generate_candidate_list(doc)\n",
    "    \n",
    "    candidate_jll_per_doc = []\n",
    "    input_seq = encoder_input_data[i:i+1]\n",
    "    \n",
    "    true_target_index = target_index(i, y_candidate, y['padded'][i])\n",
    "    \n",
    "    # Encode\n",
    "    candidate_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    for j in range(y_candidate.shape[0]):\n",
    "        candidate_seq = y_candidate[j:j+1]\n",
    "        candidate_jll_slide, candidate_last_prob = decode_sequence_target(candidate_states_value, candidate_seq)\n",
    "        candidate_jll_per_doc.append(candidate_jll_slide)\n",
    "\n",
    "    candidate_jll_per_doc = np.asarray(candidate_jll_per_doc)\n",
    "    max_jll_index = np.argmax(candidate_jll_per_doc)\n",
    "    true_target_jll = np.around(candidate_jll_per_doc[true_target_index],5)\n",
    "    max_candidate_jll = np.around(candidate_jll_per_doc[max_jll_index],5)\n",
    "    \n",
    "    \n",
    "#     file.write('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\n' %(i, true_target_index, y['text'][i],\n",
    "#                                                             max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "#                                                             -(true_target_index-max_jll_index),\n",
    "#                                                             true_target_jll, max_candidate_jll,\n",
    "#                                                             np.absolute(true_target_jll-max_candidate_jll),\n",
    "#                                                             len(intersection(y['padded'][i], y_candidate[max_jll_index])),\n",
    "#                                                             np.exp(true_target_jll/4), np.exp(max_candidate_jll/4)))\n",
    "    \n",
    "    print('%d\\t%d\\t%s\\t%d\\t%s\\t%d\\t%.5f\\t%.5f\\t%.5f\\t%d\\t%.5f\\t%.5f\\n' %(i, true_target_index, y['text'][i],\n",
    "                                                            max_jll_index, to_sequence(y_candidate[max_jll_index]),\n",
    "                                                            -(true_target_index-max_jll_index),\n",
    "                                                            true_target_jll, max_candidate_jll,\n",
    "                                                            np.absolute(true_target_jll-max_candidate_jll),\n",
    "                                                            len(intersection(y['padded'][i], y_candidate[max_jll_index])),\n",
    "                                                            np.exp(true_target_jll/4), np.exp(max_candidate_jll/4)))\n",
    "    if i % 100 == 0:\n",
    "        print('Processing document %d...' %(i))\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
