{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template for seq2seq\n",
    "\n",
    "1. Model (decoder, encoder)\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from slacker import Slacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input for Slacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to anneke@iitml.\n"
     ]
    }
   ],
   "source": [
    "from slacker import Slacker\n",
    "\n",
    "SLACK_TOKEN = 'xoxp-554173958562-554173959170-555244937223-1f3cfc06ff8cc48d3a2ea00e6c682a7c'\n",
    "\n",
    "slack = Slacker(SLACK_TOKEN)\n",
    "\n",
    "if slack.api.test().successful:\n",
    "    print(\n",
    "        f\"Connected to {slack.team.info().body['team']['name']}.\")\n",
    "else:\n",
    "    print('Try Again!')\n",
    "        \n",
    "def report_stats(text, channel):\n",
    "    \"\"\"Report training stats\"\"\"\n",
    "    r = slack.chat.post_message(channel=channel, text=text,\n",
    "                                username='Code Report',\n",
    "                                icon_emoji=':running:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Var\n",
    "GLOVE = True\n",
    "GLOVE_DIM = 100\n",
    "max_encoder_seq_length = 81\n",
    "max_decoder_seq_length = 5\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "X_train_sequence = open_pickle('../../data/imdb/X_tr_sample_original.pkl')\n",
    "X_test_sequence = open_pickle('../../data/imdb/X_te_sample_original.pkl')\n",
    "y_train_target = open_pickle('../../data/imdb/y_tr_target_original.pkl')\n",
    "y_test_target = open_pickle('../../data/imdb/y_te_target_original.pkl')\n",
    "\n",
    "if GLOVE:\n",
    "    GLOVE_DIR = \"../../data/glove.6B/\"\n",
    "\n",
    "    def extract_glove_index(file):\n",
    "        embeddings_index = {}\n",
    "        f = open(os.path.join(GLOVE_DIR, file), 'r')\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        return embeddings_index\n",
    "\n",
    "    embeddings_index = extract_glove_index('glove.6B.100d.txt')\n",
    "    print('Total %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "def preprocess(X, y):\n",
    "    tokenizer = k.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texrs(X)\n",
    "    \n",
    "    X_padded = pad_sequences(tokenizer.texts_to_sequences(X), maxlen=max_encoder_seq_length, padding='post', truncating='post')\n",
    "    y_padded = pad_sequences(tokenizer.texts_to_sequences(y), maxlen=max_decoder_seq_length, padding='post', truncating='post')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasSeq2Seq():\n",
    "    def __init__(self):\n",
    "        self.LATENT_DIM = 100\n",
    "        self.EMBEDDING_DIM = 300\n",
    "    \n",
    "    def build_model():\n",
    "        encoder_inputs = keras.layers.Input(shape=(None, self.EMBEDDING_DIM))\n",
    "        encoder = keras.layers.LSTM(self.LATENT_DIM, return_state=True)\n",
    "        \n",
    "        if bidirectional:\n",
    "            encoder = keras.layers.Bidirectional(encoder)\n",
    "            encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "            \n",
    "            state_h = keras.layers.Concatenate()([forward_h, backward_h])\n",
    "            state_c = keras.layers.Concatenate()([forward_h, backward_h])\n",
    "        else:\n",
    "            encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "        \n",
    "        encoder_state = [state_h, state_c]\n",
    "        \n",
    "        decoder_inputs = keras.layers.Input(shape=(None, self.EMBEDDING_DIM))\n",
    "        decoder_lstm = LSTM(self.LATENT_DIM, return_state=True, return_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = k.layers.Input(shape=(None, EMBEDDING_DIM))\n",
    "encoder = k.layers.Bidirectional(LSTM(int(LATENT_DIM/2), return_state=True))\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "\n",
    "state_h = k.layers.Concatenate()([forward_h, backward_h])\n",
    "state_c = k.layers.Concatenate()([forward_c, backward_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = k.layers.Input(shape=(None, EMBEDDING_DIM))\n",
    "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                    initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = k.layers.Dense(NUM_DECODER_TOKENS, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
