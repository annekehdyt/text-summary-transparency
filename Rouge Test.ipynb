{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is :0.4460580912863071\n",
      "Recall is :0.4396728016359918\n",
      "F Score is :0.44284338048664124\n"
     ]
    }
   ],
   "source": [
    "from PyRouge.PyRouge.pyrouge import Rouge\n",
    "\n",
    "r = Rouge()\n",
    "\n",
    "system_generated_summary = \"The Kyrgyz President pushed through the law requiring the use of ink during the upcoming Parliamentary and Presidential elections In an effort to live up to its reputation in the 1990s as an island of democracy. The use of ink is one part of a general effort to show commitment towards more open elections. improper use of this type of ink can cause additional problems as the elections in Afghanistan showed. The use of ink and readers by itself is not a panacea for election ills.\"\n",
    "\n",
    "manual_summmary = \"The use of invisible ink and ultraviolet readers in the elections of the Kyrgyz Republic which is a small, mountainous state of the former Soviet republic, causing both worries and guarded optimism among different sectors of the population. Though the actual technology behind the ink is not complicated, the presence of ultraviolet light (of the kind used to verify money) causes the ink to glow with a neon yellow light. But, this use of the new technology has caused a lot of problems. \"\n",
    "\n",
    "\n",
    "[precision, recall, f_score] = r.rouge_l([system_generated_summary], [manual_summmary])\n",
    "\n",
    "print(\"Precision is :\"+str(precision)+\"\\nRecall is :\"+str(recall)+\"\\nF Score is :\"+str(f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the true sequence and candidate sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2199}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "true_seq = []\n",
    "candidate_seq = []\n",
    "\n",
    "with open('jll_sample.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "            continue\n",
    "        else:\n",
    "            true_seq.append(row[2])\n",
    "            candidate_seq.append(row[4])\n",
    "            line_count += 1\n",
    "    print({line_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "[precision, recall, f_score] = r.rouge_l([true_seq[10]], [candidate_seq[10][:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is :0.8518518518518519\n",
      "Recall is :0.8518518518518519\n",
      "F Score is :0.8518528018518547\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision is :\"+str(precision)+\"\\nRecall is :\"+str(recall)+\"\\nF Score is :\"+str(f_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('out loud funny watching her', 'loud funny watching her cry')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_seq[10], candidate_seq[10][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_seq[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_seq[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_one(true, candidate):\n",
    "    \n",
    "    if isinstance(true, str) and isinstance(candidate, str):\n",
    "        true = true.split()\n",
    "        candidate = candidate.split()\n",
    "    \n",
    "    overlap = [value for value in true if value in candidate] \n",
    "    \n",
    "    recall = len(overlap)/len(true)\n",
    "    precision = len(overlap)/len(candidate)\n",
    "    f1 = 2*((recall*precision)/(recall+precision))\n",
    "    \n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_one(true_seq[10], true_seq[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 'an', '8/10', 'but', \"let's\"]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = 'it an 8/10 but let\\'s'.split()\n",
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it', 'an', '8/10', 'but', \"let's\"], ['it', 'an', '8/10', 'but', \"let's\"]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[true, true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = true + true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 'an', '8/10', 'but', \"let's\", 'it', 'an', '8/10', 'but', \"let's\"]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'8/10', 'an', 'but', 'it', \"let's\"}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
